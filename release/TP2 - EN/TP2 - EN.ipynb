{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/1/1d/Logo_T%C3%A9l%C3%A9com_SudParis.svg/1014px-Logo_T%C3%A9l%C3%A9com_SudParis.svg.png\" width=\"30%\"></img>\n",
    "</center>\n",
    "\n",
    "<center> <h2> NET 4103/7431 Complex Network </h2> </center>\n",
    "\n",
    "<center> <h3> Vincent Gauthier (vincent.gauthier@telecom-sudparis.eu) </h3> </center>\n",
    "\n",
    "### Note\n",
    "Avant de commencer les exercices, assurez-vous que tout fonctionne comme prévu. Tout d'abord, le redémarrage du kernel **(dans la barre de menus, sélectionnez le kernel $\\rightarrow$ Restart)**.\n",
    "\n",
    "Assurez-vous que vous remplir les célluler aux endroits marquer «YOUR CODE HERE». \n",
    "\n",
    "Veuillez supprimer les ligne «raise NotImplementedError()» dans toutes les cellules auxquelles vous avez répondu, ainsi que votre nom et prénom ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NOM = \"XXX\"\n",
    "PRENOM = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">TP 2: L'algorithme du PageRank</h3> \n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<img src=\"../../images/webmap.jpg\"></img>\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Before 1998, the web graph was a largely unused source of information and ignored by search engines such as Yahoo, or Astalavista. However, researchers such as Jon Kleinberg [2] and Brin and Page [3] have used this resource to create an algorithmically elegant methodology that has helped develop the search engines we know today. They then mainly used the following idea: a hyperlink link from my web page to another page can be interpreted as a recommendation from me to the web page in question. The underlying idea that is exploited is the following: a web page that is quoted very often must have a better ranking than a less frequently cited web page. However, this idea is not new, but used as the sole selective criterion is not enough. For example, a letter of recommendation for a job from the CEO of Orange will surely carry more weight than the other 10 letters of recommendation that you could have received from random people. In conclusion, the importance of the recommendations (and not only their numbers) must also be taken into account in calculating the reputation of a web page. This is exactly the principle of **PageRank**.\n",
    "\n",
    "In current search engines, each indexed webpage is associated with a \"**PageRank**\" value. When you perform a search, the search engine returns the web pages corresponding to the keywords sorted in ascending order of their value of \"PageRank\". The underlying assumption that is used is that: the web page with the highest \"PageRank\" value must be the most relevant for the keywords considered.\n",
    "\n",
    "In short, the notoriety (PageRank value) of a web page is defined as follows: the reputation of a web page is important, if it is itself pointed by other web pages with significant notoriety. This circular reasoning is at the heart of the algorithm that will be developed during this exercise. Through this circular reasoning, we deduce that the values of PageRank are in fact the values of the stationary states of an immense Markov chain. The transitions of this Markov chain are defined by the web graph. The matrix of transitions of this Markov chain is called \"Google\" matrix $\\mathbf{G}$. In order to calculate this stationary state vector, however, the Markov chain in question must have a unique solution. For this, one of the conditions is that the transitions graph must be irreducible (ie the graph forms a connected component), which is not the case for the web graph (cf. Fig. 1). The PageRank algorithm allowed Brin and Page to intelligently bypass this difficulty applying a transformation on the adjacency matrix in order to assume the irreducibility of this one.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/Scc.png\" width=\"500px\"></img>\n",
    "** Figure 1**\n",
    "</div>\n",
    "\n",
    "**PageRank's Algorithm**\n",
    "1. Normalization of the adjacency matrix of the web graph to generate a stochastic matrix\n",
    "2. we update the matrix from the previous step in order to take into account the Dangling nodes (the node that don't have any outgoing link)\n",
    "3. Create the \"Google\" Matrix\n",
    "4. Compute the stationary state of the Markov chain\n",
    "\n",
    "In the first part of this exiercice we are going to considere the follwing directed graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (cf. **Fig. 2**), as small example of the web graph. Each edge $e \\in \\mathcal{E}$ represente one hyperlink from one webpage $v \\in \\mathcal{V}$ to another.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/GraphPageRank.png\" width=\"400px\"></img>\n",
    "**Figure 2**\n",
    "</div>\n",
    "\n",
    "### Notations\n",
    "$\\mathbf{A}$: The adjacency matrix of the graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$\n",
    "\n",
    "$\\mathbf{H}$: Normalized adjacency matrix\n",
    "\n",
    "$\\mathbf{G}$: The dense, stochastic matrix called teh \"Google\" matrix\n",
    "\n",
    "$\\mathbf{\\pi}^T$: PageRank Vector, a stationnay vector of the Markov chain describe by the matrix $\\mathbf{G}$\n",
    "\n",
    "$n$ : Number of the web page (in our graph)\n",
    "\n",
    "$\\alpha$: parameter between 0 and 1\n",
    "\n",
    "### Conventions\n",
    "\n",
    "$\\mathbf{e}^T$ : is vector line $\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}$\n",
    "\n",
    "$\\mathbf{e}$ : is a vector colomn  $\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$\n",
    "\n",
    "$\\sigma(\\mathbf{A})$ est l'ensemble (set) des valeurs propres de la matrice $\\mathbf{A}$\n",
    "\n",
    "$\\lambda_{max} = \\max_{\\lambda \\in \\sigma(\\mathbf{A})} \\lvert \\lambda \\lvert$ est la plus grande valeur propre de la matrice $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{e} \\otimes \\mathbf{e}^T$ : est le produit exterieur $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3  \\end{pmatrix}  \\otimes \\begin{pmatrix} 1 & 2 & 3 \\end{pmatrix} = \\begin{pmatrix} 1 & 2 & 3  \\\\ 2 & 4 & 6 \\\\ 3 & 6 & 9 \\end{pmatrix}$\n",
    "\n",
    "### Python Reminder \n",
    "Multiplication and division with Numpy:\n",
    "```Python\n",
    "import numpy as np\n",
    "x = np.array([2, 2, 2])\n",
    "2*x\n",
    ">>> array([4, 4, 4])\n",
    "x = np.array([2, 2, 2])\n",
    "x/2\n",
    ">>> array([1, 1, 1])\n",
    "A = np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]])\n",
    "A/2\n",
    ">>> np.array([[1, 1, 1], \n",
    "              [1, 1, 1], \n",
    "              [1, 1, 1]])\n",
    "```\n",
    "\n",
    "Matrix vector division:\n",
    "```Python\n",
    "A = np.array([[1, 1], [4, 4]])\n",
    "b = np.array([1, 3])\n",
    "(A.T/b).T\n",
    ">>> array([[ 1.        ,  1.        ],\n",
    "           [ 1.33333333,  1.33333333]])\n",
    "```\n",
    "\n",
    "Dot product:\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 2, 2], [2, 2, 2]])\n",
    "x = np.array([2, 2, 2])\n",
    "np.dot(A,x)\n",
    ">>> array([12, 12])\n",
    "\n",
    "a = np.array([1, 1, 1])\n",
    "b = np.array([1, 1, 1])\n",
    "np.outer(a,b)\n",
    ">>> array([[1, 1, 1], \n",
    "           [1, 1, 1], \n",
    "           [1, 1, 1]])\n",
    "```\n",
    "\n",
    "Matrix transpose:\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "A.T\n",
    ">>> array([[1, 3],\n",
    "           [2, 4]])\n",
    "```\n",
    "\n",
    "Shape of a matrix\n",
    "```Python\n",
    "A = np.array([[1, 1, 1], [1, 1, 1]])\n",
    "n, m = A.shape\n",
    "print(n, m)\n",
    ">>> 2 3\n",
    "```\n",
    "\n",
    "Row sum of a Matrix\n",
    "```Python\n",
    "A = np.array([[1, 1, 1,], [2, 2, 2]])\n",
    "A[1,:].sum()\n",
    ">>> 6\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Style pour le Notebook\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a synthetic web-graph with networkx\n",
    "\n",
    "With the help of networkx generate the directed graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (cf. **Fig 2**), and draw the graph with matplotlib in order to validate visualy that you obtain the same graph as in the **figure 2**. \n",
    "\n",
    "**Help**: Use the already defined functions in the networkx library to add vertices and edges to the graph ([networkx tutorial](https://networkx.github.io/documentation/networkx-1.10/tutorial/tutorial.html#nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce5deac44e9dcdf79565f93d9e750dac",
     "grade": false,
     "grade_id": "cell-b38b9e2b9a5a33ff",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "g = nx.DiGraph()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "pos = nx.spring_layout(g);\n",
    "nx.draw_networkx(g, pos=pos, node_size=600, font_size=20.0);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff2b2087ce0fad434bdc059c5fc2b5c3",
     "grade": true,
     "grade_id": "cell-eb40bde129593b4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(g.nodes()) == 6\n",
    "assert g.has_edge(6,4)\n",
    "assert g.has_edge(4,6)\n",
    "assert g.has_edge(2,5) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the Adjacency matrix of the graph \n",
    "\n",
    "Before going further in the exercise, let's extract the adjacency matrix $\\mathbf{A}_{n \\times n}$ from the directed graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ to construct the normalized adjacency matrix of the $\\mathbf{H}_{n \\times n} $ graph.\n",
    "\n",
    "(eq. **1**)\n",
    "$$\n",
    "\\mathbf{H}_{ij} = \\begin{cases}\n",
    "    1/\\sum_{j} \\mathbf{A}_{ij} & \\text{ if there is a link between node } i \\text{ and } j\\\\\n",
    "    0 & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Exemple**: The matrix $\\mathbf{H}_{n \\times n}$ of the graph in figure 2.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\begin{pmatrix}\n",
    "  0 & 1/2 & 1/2 & 0 & 0 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "  1/3 & 1/3 & 0 & 0 & 1/3 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 1/2 & 1/2 \\\\\n",
    "  0 & 0 & 0 & 1/2 & 0 & 1/2 \\\\\n",
    "  0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Example: How to export the adjacency matrix from a networkx graph**\n",
    "```Python\n",
    ">>> import numpy as np\n",
    ">>> G = nx.Graph([(1,1)])\n",
    ">>> A = nx.to_numpy_matrix(G)\n",
    ">>> A\n",
    "matrix([[ 1.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33deec33a20f0cd30da411e804e74047",
     "grade": false,
     "grade_id": "cell-a559fbd8ae7bdf62",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_stochatic(G):\n",
    "    ### Ignore division by zero warmings\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e33b6225c08fd8172fe784694ed0825b",
     "grade": true,
     "grade_id": "cell-b603cb0d07644bd0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "H = transform_to_stochatic(g)\n",
    "\n",
    "H_res = np.array( \n",
    "[[ 0.,          0.5,         0.5,         0.,          0.,          0.,        ],\n",
    " [ 0.,          0.,          0.,          0.,          0.,          0.,        ],\n",
    " [ 0.33333333,  0.33333333,  0.,          0.,          0.33333333,  0.,        ],\n",
    " [ 0.,          0.,          0.,          0.,          0.5,         0.5,       ],\n",
    " [ 0.,          0.,          0.,          0.5,         0.,          0.5,       ],\n",
    " [ 0.,          0.,          0.,          1.,          0.,          0.,        ]])\n",
    "\n",
    "np.testing.assert_allclose(H, H_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding dangling nodes \n",
    "\n",
    "We want to calculate the \"dangling vector\" $\\mathbf{a}$ which associates with each node the value 1 if this one does not have any outgoing link, and 0 otherwise.\n",
    "\n",
    "(eq. **2**)\n",
    "\n",
    "$$\n",
    "\\mathbf{a}_i = \\begin{cases}\n",
    "    1 & si \\sum_{j} \\mathbf{A}_{ij} = 0 \\\\\n",
    "    0              & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Example**:\n",
    "<img src=\"../../Images/DanglingPageRank.png\" width=\"500px\"></img>\n",
    "<div align=\"center\"><b>Figure 3</b>: the correponding vector $\\mathbf{a}$ of the graph defined in figure 2.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c34e179bdc0905e6995ebbeac203b9d5",
     "grade": false,
     "grade_id": "cell-16160fe83dc86883",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def dangling_vector(H):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8e49c909b22b7fc7d393f42ec49e7b4",
     "grade": true,
     "grade_id": "cell-4c9063860247f96f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "a = dangling_vector(H)\n",
    "np.testing.assert_array_equal(a, [ 0.,  1.,  0.,  0.,  0.,  0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the \"Google\" Matrix \n",
    "\n",
    "Unfortunately, the graph of the web does not form a connected graph, which is neither irreducible nor aperiodic. By constructing the \"Google\" matrix, we will add artificial transitions to the adjacency matrix of the web graph in order to transform it into another graph that offers satisfactory properties (irreducible and aperiodic). Once the $ \\mathbf{G}_{n \\times n}$ matrix has been built, it will be used to calculate the steady states $\\pi^T$ (the PageRank) of each node of the graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$. The goal of this exercise is to transform the $\\mathbf{A}_{n \\times n}$ adjacency matrix of the web graph into a matrix $\\mathbf{G}_{n \\times n}$ so that it satisfies the following conditions:\n",
    "\n",
    "1. The matrix $\\mathbf{G}$ should be stochastic. \n",
    "2. The matrix $\\mathbf{G}$ should be irreductible.\n",
    "3. The matrix $\\mathbf{G}$ should be aperiodic.\n",
    "4. The matrix $\\mathbf{G}$ should be primitive. \n",
    "\n",
    "<div class=warn>\n",
    "<b>Definition:</b> A matrix is called primitive if it admits a power whose terms are strictly positive (i.e., there is $ \\mathbf{G}^k > 0 $).\n",
    "</div>\n",
    "\n",
    "<div class=warn>\n",
    "<b>Theorem:</b> if the matrix $\\mathbf{G}$ is primitive the it exist a vector $\\pi^{(k)T}$ such that $\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(k)T} \\mathbf{G}$. In other words, there is convergence of the vector $\\pi^{(k)}$ to a single stationary state when $k \\to \\infty$, see Perron-Frobenius theorem.\n",
    "</div>\n",
    "\n",
    "<div class=warn>\n",
    "<b>Theorem of Perron-Frobenius:</b> Let $ \\mathbf{A} $ be a positive and primitive matrix. Then there exist a value $ \\lambda_{max}$ such that:\n",
    "\n",
    "1. $\\lambda_{max}$ is a real positive value, $\\lambda_{max} > 0$ <br>\n",
    "2. $\\lambda_{max}$ is associated to eigenvectors strictly positive <br>\n",
    "3. $\\lambda_{max} > \\lvert \\lambda \\lvert\\ \\ \\forall \\lambda \\neq \\lambda_{max}$ <br>\n",
    "4. it exist a unique vector $\\mathbf{x}$ (with $\\lvert\\lvert \\mathbf{x} \\lvert\\lvert_{1} = 1$) such that  $\\mathbf{A}\\mathbf{x}=\\lambda_{max} \\mathbf{x}$\n",
    "</div>\n",
    "\n",
    "<div class=green>\n",
    "<b>Conclusion:</b> the adjacency matrix $\\mathbf{A}_{n \\times n}$ of an ireductible and aperiodic graph is a primitve matrix. Alors d'après le thèoreme de Perron-Frobenius on peut en conclure que la matrice d'adjacence $\\mathbf{A}_{n \\times n}$ admet un unique vecteur $\\mathbf{x}$ de norme 1 à coordonnées strictement positives tel que $\\mathbf{A}\\mathbf{x}=\\lambda_{max} \\mathbf{x}$.\n",
    "</div>\n",
    "\n",
    "On pose :\n",
    "\n",
    "(eq. **3**)\n",
    "$$\n",
    "\\mathbf{S} = \\mathbf{H} + \\frac{1}{n} \\mathbf{a} \\otimes \\mathbf{e}^T \\\\\n",
    "$$\n",
    "\n",
    "Pour rappel, le vecteur $\\mathbf{a}_n$ (calculé à l'étape 3. de l'exercice) est le vecteur Dangling et $\\mathbf{H}_{n \\times n}$ est la matrice normalisée d'adjacence du graphe orienté $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (calculé à l'étape 2. de l'exercice). On definit la matrice alors la \"Google matrice\" comme étant: \n",
    "\n",
    "(eq. **4**)\n",
    "$$\n",
    "\\mathbf{G} = \\alpha  \\mathbf{S} + (1-\\alpha) \\frac{1}{n}\\mathbf{e} \\otimes \\mathbf{e}^T \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../../images/GoogleMatrice.png\" width=\"700px\"></img>\n",
    "<div align=\"center\">**Fig. 4**: Google matrice</div>\n",
    "\n",
    "La \"Google matrice\" $\\mathbf{G}_{n \\times n} $ (cf. eq. 4) est construite en ajoutant des transitions supplémentaires (cf. Fig. 3) à la matrice d'adjacence originale du graphe $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ de telle sorte que les conditions 1 à 3 soient satisfaites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: Développé l'équation 4 (à l'aide de l'équation 3) afin d'exprimer la matrice $\\mathbf{G}_{n \\times n}$ en fonction de $\\mathbf{H}_{n \\times n}$ et $\\mathbf{a}_n$\n",
    "\n",
    "\n",
    "**reponse**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implémenter la fonction qui construit la \"Google matrice\"  (reponse de la question 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "236c6df70dabc362daa551c076e1cd44",
     "grade": false,
     "grade_id": "cell-a6428e1d936486ec",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def google_matrix(H, a, α=0.9):\n",
    "    '''\n",
    "    H: matrix d'adjacence stochastique\n",
    "    a : Dangling vector\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3911ba920c7cef96cde7b015ad3cc842",
     "grade": true,
     "grade_id": "cell-879580d18840fc1e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "G = google_matrix(H, a)\n",
    "print(G)\n",
    "\n",
    "G_res = np.array(\n",
    "[[ 0.01666667,  0.46666667,  0.46666667,  0.01666667,  0.01666667,  0.01666667],\n",
    " [ 0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667],\n",
    " [ 0.31666667,  0.31666667,  0.01666667,  0.01666667,  0.31666667,  0.01666667],\n",
    " [ 0.01666667,  0.01666667,  0.01666667,  0.01666667,  0.46666667,  0.46666667],\n",
    " [ 0.01666667,  0.01666667,  0.01666667,  0.46666667,  0.01666667,  0.46666667],\n",
    " [ 0.01666667,  0.01666667,  0.01666667,  0.91666667,  0.01666667,  0.01666667]])\n",
    "\n",
    "np.testing.assert_allclose(G, G_res, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application numerique pour le graphe décrit dans la figure 2 ($\\alpha = 0.9$)\n",
    "\n",
    "(**eq. 4.**)\n",
    "$$\n",
    "\\mathbf{G} = 0.9\\mathbf{H} + \\left[ 0.9 \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{pmatrix} + 0.1  \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ \\end{pmatrix}  \\right]  \\otimes 1/6  \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 & 1 \\end{pmatrix} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{G} =  \\begin{pmatrix} \n",
    "1/60 & 7/15 & 7/15 & 1/60 & 1/60 & 1/60 \\\\\n",
    "1/6  & 1/6  & 1/6  & 1/6  & 1/6  & 1/6 \\\\\n",
    "19/60 & 19/60 & 1/60 & 1/60 & 19/60 & 1/60 \\\\\n",
    "1/60 & 1/60 & 1/60 & 1/60 & 7/15 & 7/15 \\\\\n",
    "1/60 & 1/60 & 1/60 & 7/15 & 1/60 & 7/15 \\\\\n",
    "1/60 & 1/60 & 1/60 & 11/12 & 1/60 & 1/60 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculer la valeur du vecteur PageRank\n",
    "\n",
    "(**eq. 5**)\n",
    "\\begin{eqnarray}\n",
    "& \\mathbf{\\pi}^{(k)T} & =   \\mathbf{\\pi}^{(k-1)T} \\mathbf{G} \\\\ \n",
    "& \\mathbf{\\pi}^{(k-1)T} & = \\mathbf{\\pi}^{(k-2)T} \\mathbf{G} \\\\ \n",
    "& \\vdots &\\\\\n",
    "& \\mathbf{\\pi}^{(1)T} & = \\mathbf{\\pi}^{(0)T} \\mathbf{G} \n",
    "\\end{eqnarray}\n",
    "\n",
    "Par récurence on peut donc écrire \n",
    "\n",
    "(**eq. 6**)\n",
    "$$\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(0)T} \\mathbf{G}^k$$\n",
    "\n",
    "On cherche maintenant à calculé le vecteur stationnaire $\\mathbf{\\pi}^{(k)T}$ lorsque $k \\to \\infty$. On sait que la matrice $\\mathbf{G}$ est primitive par construction, alors la converge du vecteur $\\mathbf{\\pi}^{T}$(dans le cas d'un espace d'état fini) est prouvé par le théorème de Perron-Frobenius. Afin de calculer les états stationaires du vecteur $\\mathbf{\\pi}^{T}$ on va alors itérer l'opération $\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(k-1)T} \\mathbf{G}$ jusqu'a convergence du vecteur $\\mathbf{\\pi}^{T}$ (cf. Alg 1).\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"../../images/PowerIt.png\" width=\"600px\"></img>\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">**Alg1** : Algorithme de calcule iteratif du PageRank</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ceecbc8e275f13b2271393cb5e19cd2",
     "grade": false,
     "grade_id": "cell-0f2de665f401ce93",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def power_iter(G, max_iter=500, tol=1e-6):\n",
    "    \"\"\"power_iter\n",
    "\n",
    "    Parametres\n",
    "    -----------\n",
    "    G : Goole matrice\n",
    "\n",
    "    max_iter : integer, optional\n",
    "        Nombre maxium d'iteration permise \n",
    "\n",
    "    tol : float, optional\n",
    "       Error tolerance used to check convergence in power method solver.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    raise RuntimeError('pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e55e1132cfcaa077d1d123b2a87a4da1",
     "grade": true,
     "grade_id": "cell-30e261076683cffa",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(π, gap) = power_iter(G, max_iter=100, tol=1e-6)\n",
    "print(π)\n",
    "\n",
    "π_res = np.array([ 0.03721313,  0.05395937,  0.04150701,  0.37507848,  0.20599777,  0.28624425])\n",
    "\n",
    "np.testing.assert_allclose(π, π_res, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ, _ = LA.eig(G)\n",
    "λ_2 = np.sort(λ.real)[-2]\n",
    "λ_gap = [λ_2 ** i for i in range(1,25)]\n",
    "\n",
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.semilogy(gap, 'ro')\n",
    "plt.semilogy(λ_gap, lw=2.0, label=\"$\\lambda_2^i$\")\n",
    "plt.title(\"Vitesse de convergence de l'algorithme du PageRank\")\n",
    "plt.xlabel(\"Nombre d'iterations de l'agorithme PageRank $(i)$\")\n",
    "plt.ylabel(\"iteration gap\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "print(π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Intégration des trois étapes qui constituent l'algorithme du PageRank\n",
    "\n",
    "Construire la fonction qui intégre les différentes étapes qui constitutent l'algorithme du PageRank. Vous allez utiliser les fonctions que vous avez définies précedemment pour construire l'algorithme final. \n",
    "\n",
    "**Algorithme du PageRank**\n",
    "1. Normalisation de la matrice d'ajacence du graphe du web\n",
    "2. Découverte des noeuds du graphe du web ne possédant pas de liens de sortie \"Dangling nodes\"(aucun lien hypertext)\n",
    "3. Creation de la \"Google\" Matrice \n",
    "4. Calcul de la vecteur des états stationnaires de la chaine de Markov $\\mathbf{G}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e9bed3c1b8d0a0ef40b46065e5e3f54",
     "grade": false,
     "grade_id": "cell-4db00d895b96dc80",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pagerank(Graph, α=0.85, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Return the PageRank of the nodes in the graph.\n",
    "\n",
    "    PageRank computes a ranking of the nodes in the graph G based on\n",
    "    the structure of the incoming links. It was originally designed as\n",
    "    an algorithm to rank web pages.\n",
    "\n",
    "    Parametres\n",
    "    -----------\n",
    "    G : graph\n",
    "      A NetworkX graph.  Undirected graphs will be converted to a directed\n",
    "      graph with two directed edges for each undirected edge.\n",
    "\n",
    "    alpha : float, optional\n",
    "      Damping parameter for PageRank, default=0.85.\n",
    "\n",
    "    max_iter : integer, optional\n",
    "      Maximum number of iterations in power method.\n",
    "\n",
    "    tol : float, optional\n",
    "      Error tolerance used to check convergence in power method solver.\n",
    "      \n",
    "    Return\n",
    "    PR : dict\n",
    "      retourne un dictionnaire avec comme clé le nodeid, et comme valeur le pagerank du noeud \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e130eb2b8901bc945487baa044fc572c",
     "grade": true,
     "grade_id": "cell-0fb3eb924a1dcb99",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "PR = pagerank(g)\n",
    "print(PR)\n",
    "\n",
    "PR_res = dict({\n",
    "    1: 0.05170556259095016, \n",
    "    2: 0.07368068204240269, \n",
    "    3: 0.057413363969125462, \n",
    "    4: 0.3487020460725242, \n",
    "    5: 0.1999034157779406, \n",
    "    6: 0.2685949295470571})\n",
    "\n",
    "for k,v in PR_res.items():\n",
    "    np.testing.assert_allclose(PR[k], PR_res[k], rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application de l'algorithme du PageRank pour le classement des pages web\n",
    "\n",
    "## Exemple avec le graphe des liens du site Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge le graphe des liens des page wikipedia dans un graphe (networkx)\n",
    "Gwikipedia = nx.read_graphml(\"../../Data/Wikipedia/wikipedia.graphml\")\n",
    "\n",
    "#On charge la base de données des pages dans un tableau Pandas\n",
    "wikipedia_db = pd.read_pickle(\"../../Data/Wikipedia/wikipedia.db\")\n",
    "wikipedia_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcule des propriété statistique du graphe les liens des pages wikipedia \n",
    "\n",
    "Nous allons calculer:\n",
    "1. la densité du graphe (rappel la densité d'un graphe $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ est $D =\\vert \\mathcal{E}\\vert/N(N-1)$) \n",
    "2. la densité de probabilité empirique du degré des noeuds du graphe \n",
    "3. le complémentaire de la fonction de répartition empirique du degré des noeuds du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61fdbe9a3820e98aec32645ce5f4c43d",
     "grade": true,
     "grade_id": "cell-35511977dcf07d47",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#question 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# On calcule la distribution des degree du graphe des pages wikipedia question 2 et 3\n",
    "#\n",
    "degree = [v for k,v in dict(Gwikipedia.degree()).items()]\n",
    "distribution = [(elem, degree.count(elem)) for elem in sorted(set(degree))]\n",
    "k,pk = zip(*distribution)\n",
    "PDF = np.array(pk)/sum(pk)\n",
    "CCDF = 1-np.cumsum(PDF)\n",
    "\n",
    "\n",
    "#\n",
    "# Afichage \n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.loglog(k, PDF, 'ro')\n",
    "ax1.set_xlabel(\"$k$ Degree\")\n",
    "ax1.set_ylabel(\"$P_k$\")\n",
    "ax1.set_title(\"PDF\")\n",
    "\n",
    "ax2.loglog(k, CCDF, 'ro')\n",
    "ax2.set_ylim(1e-4,1.1)\n",
    "ax2.set_xlim(1,2e3)\n",
    "ax2.set_xlabel(\"$k$ Degree\")\n",
    "ax2.set_ylabel(\"$1-P[K > k]$\")\n",
    "ax2.set_title(\"CCDF\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question:**\n",
    "\n",
    "- La matrice d'adjacence du graphe est-elle dense ? ou au contraire creuse ?\n",
    "- Que dire de la distribution du degrée des articles wikipedia ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculer le PageRank du graphe des articles  Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09138e5ab7e4ec01911517cb6f7bb587",
     "grade": true,
     "grade_id": "cell-2abb4f66eee73d43",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Calcul du PageRank en utilisant la fonction PageRank déja implementé\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "PR = [[k,v] for k,v in PR.items()]\n",
    "PR = pd.DataFrame(PR, columns=['PageID', 'PageRank'])\n",
    "PR = PR.set_index('PageID')\n",
    "PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On associe un PageRank à chaque page wikipedia dans la base de données \n",
    "wikipedia_db = wikipedia_db.join(PR)\n",
    "# On trie les entrées wikipedia par ordre croissant de leur PageRank\n",
    "wikipedia_db = wikipedia_db.sort_values(['PageRank'], ascending=0)\n",
    "# on affiche les premières entrées triées par ordre croissant \n",
    "wikipedia_db[[\"Page Title\", \"PageRank\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effectuer une recherche par mots clés sur la base de données des articles Wikipedia\n",
    "\n",
    "**Attention**: le nombre de pages wikipedia indexées dans cette base de données est de l'ordre de 5000 articles seulement, rédigé en anglais. Le nombre d'articles et donc de mots clées sont donc restreints. Effectuer les requêtes avec des mots clés ecrit en lettres minuscules uniquements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de mots cléss \n",
    "mot_clee_1 = \"france\"\n",
    "mot_clee_2 = \"germany\"\n",
    "# Requete sur la base de données par mots clés\n",
    "wikipedia_db[(wikipedia_db['Keywords'].str.contains(mot_clee_1)==True) & (wikipedia_db['Keywords'].str.contains(mot_clee_2)==True)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de mots clées \n",
    "mot_clee_1 = \"france\"\n",
    "# Requete sur la base de données par mots clée\n",
    "wikipedia_db[(wikipedia_db['Keywords'].str.contains(mot_clee_1)==True) ].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**:\n",
    "\n",
    "Effectuez conjointement: une requête sur la base de donnée et avec le moteurs de recherche de google: \n",
    "\n",
    "* Faite une Requete google \"site:wikipedia.org mot_clée1 mot_clée2\"\n",
    "* Comparer qualitativement les requetes faite sur Google et celles effectués sur la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation du PageRank avec un algorithme distribué\n",
    "\n",
    "\n",
    "Le classement des page web au travers de l'algorithme du \"PageRank\" est encore aujourd'hui considéré comme étant le plus gros problème matriciel connu a ce jour. Pour vous donner un ordre de grandeur, en 2007 la \"power iteration\" qui permetait le calcul du PageRank chez Google occupait un datacenter pendant 15 jours pour finaliser le calcul. Afin de reduire la complexité du calcul $\\pi^T \\mathbf{G}$ on souhaiterait effectuer un calcul sur une matrice creuse à la place de la matrice $\\mathbf{G}$ qui est dense. Dans le même temps, on souhaite pouvoir paralléliser le calcul (multiprocesseur, cluster de calcul). Une manière élégante d'obtenir ces deux propriétés est d'éffectuer l'opération suivante sur tout les noeuds du graphe (Cf. eq. 7., Fig. 5, Algo. 3):\n",
    "<br>\n",
    "(**eq. 7**)\n",
    "$$ PR_{i} = \\frac{(1-\\alpha)}{n} + \\alpha \\sum_{j \\in \\mathcal{N}(i)} \\frac{PR_j}{L_j}$$\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/PageRankDistributed2.png\" width=\"400px\"></img>\n",
    "** Figure 5.**: PageRank \n",
    "</div>\n",
    "\n",
    "L'opération decrite dans l'equation 7. peut être calculer de manière indépendante (en parallèle) pour tous les noeuds du graphes. C'est l'approche qui est développée dans des logiciels pour de calcul de grands volumes de données tels que: \n",
    "\n",
    "* [Spark/Graphx](http://spark.apache.org/)\n",
    "* [Graphlab](https://dato.com/)\n",
    "\n",
    "ou plus simplement dans certaines librairies de calcul parallèle utilisant la thèorie des graphes:\n",
    "\n",
    "* [boost graph](http://www.boost.org/doc/libs/1_46_0/libs/graph_parallel/doc/html/page_rank.html)\n",
    "* [graph-tool](https://graph-tool.skewed.de/)\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/PageRankDistributed.png\" width=\"500px\"></img>\n",
    "** Algo 3.**: Algorithme simplifié du PageRank\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5875793d6c3049551e52f6076799aed6",
     "grade": false,
     "grade_id": "cell-2143b85bf96cee6b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pagerank_distributed(g, α=0.9, max_iter=200, tol=1e-6):\n",
    "    N = len(g.nodes())\n",
    "    gc = g.copy()\n",
    "    \n",
    "    # on modifie le graphe pour ajouter les transitions au dangling node  \n",
    "    for dangling in g.nodes():\n",
    "        if gc.out_degree(dangling) == 0:\n",
    "            for n in g.nodes():\n",
    "                gc.add_edge(dangling, n)\n",
    "\n",
    "    # on initialise le pagerank a chaque noeud du graphe\n",
    "    for node in gc.nodes():\n",
    "        gc.node[node]['PageRankOld'] = 1.0/N\n",
    "    \n",
    "    # Power iteration\n",
    "    for _ in range(max_iter):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if tol > N*diff:\n",
    "            return np.array([gc.node[n]['PageRank'] for n in gc.nodes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67530456711dbd224a16f2e67ae9a4e6",
     "grade": true,
     "grade_id": "cell-78c2b295e77e9df0",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "PR = pagerank_distributed(g)\n",
    "print(PR)\n",
    "\n",
    "PR_res = np.array([\n",
    "    0.0372119873811025, \n",
    "    0.05395738811699192, \n",
    "    0.04150567933532273, \n",
    "    0.37508077029418346, \n",
    "    0.20599832111968525, \n",
    "    0.28624585375271416])\n",
    "\n",
    "np.testing.assert_allclose(PR, PR_res, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Amy N. Langville, Carl D. Meyer, \"[Deeper Inside PageRank](http://projecteuclid.org/euclid.im/1109190965)\", Internet Math., Vol. 1(3), pp. 335--380, 2003.\n",
    "\n",
    "[2] Jon Kleinberg, \"[Authoritative sources in a hyperlinked environment](http://www.cs.cornell.edu/home/kleinber/auth.pdf)\",  Journal of the ACM, 46(5), pp. 604–632, 1999.\n",
    "\n",
    "[3] L. Page, S. Brin, R. Motwani, T. Winograd, \"[The PageRank citation ranking: Bringing order to the Web](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf)\", published as a technical report on January 29, 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

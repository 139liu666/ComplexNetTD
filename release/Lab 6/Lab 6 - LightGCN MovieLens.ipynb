{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846e8048",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/1/1d/Logo_T%C3%A9l%C3%A9com_SudParis.svg/1014px-Logo_T%C3%A9l%C3%A9com_SudParis.svg.png\" width=\"10%\" />\n",
    "</center>\n",
    "\n",
    "<center> <h2> NET 4103/7431 Complex Network </h2> </center>\n",
    "\n",
    "<center> <h3> Vincent Gauthier (vincent.gauthier@telecom-sudparis.eu) </h3> </center>\n",
    "\n",
    "### Note\n",
    "Avant de commencer les exercices, assurez-vous que tout fonctionne comme prévu. Tout d'abord, le redémarrage du kernel **(dans la barre de menus, sélectionnez le kernel $\\rightarrow$ Restart)**.\n",
    "\n",
    "Assurez-vous que vous remplir les célluler aux endroits marquer «YOUR CODE HERE». \n",
    "\n",
    "Veuillez supprimer les ligne «raise NotImplementedError()» dans toutes les cellules auxquelles vous avez répondu, ainsi que votre nom et prénom ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121df80",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NOM = \"XXX\"\n",
    "PRENOM = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673bd08",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f14eeea-3983-4c64-9803-b0c8b0924aa6",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lab #6: Building Recommander System (RecSys) With LightGCN</h1> \n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<img src=\"../../images/network.png\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fe21e-1fb0-4b06-bfcc-4fe788fb5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataset import MovieLensSmall\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "# Style pour le Notebook\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588e692-3217-4752-b581-0b411bbebc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from packaging import version\n",
    "import sys \n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"networkx version:\", nx.__version__)\n",
    "print(\"torch versions:\", torch.__version__)\n",
    "print(\"torch versions:\", torch_geometric.__version__)\n",
    "\n",
    "# assert networkx version is greater or equal to 3.0\n",
    "assert version.parse(nx.__version__) >= version.parse(\"3.0\")\n",
    "assert version.parse(torch.__version__) >= version.parse(\"2.0\")\n",
    "assert version.parse(torch_geometric.__version__) >= version.parse(\"2.5\")\n",
    "# assert python version is greater that 3.9\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 9  \n",
    "\n",
    "# If working in colab mount the drive filesystem \n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Working in colab')\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"working locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563eb0c-2b7d-403b-8223-44f1da6b485a",
   "metadata": {},
   "source": [
    "## LightGCN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e7bf3-a6de-416f-bf15-f2b0903cd4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "class LGConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr='add')\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        # Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]   \n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "        return out \n",
    "        \n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1,1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99354c5b-9ad7-4e2e-812d-f3825252560b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5658febcfa0c61a81677ef5803e95e0",
     "grade": true,
     "grade_id": "cell-77e994f791d788e7",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.n_node = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = num_layers\n",
    "        self.alpha = torch.tensor(1. / (self.K + 1))\n",
    "        self.node_emb = nn.Embedding(num_embeddings=self.n_node,  embedding_dim=self.embedding_dim)\n",
    "        self.convs = nn.ModuleList([LGConv() for _ in range(self.K)])\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.node_emb.weight, std=0.1)\n",
    "\n",
    "    def get_embedding(self, edge_index):\n",
    "        # Eq.8 in the LightGCN paper https://arxiv.org/pdf/2002.02126\n",
    "        x = self.node_emb.weight\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return out\n",
    "        \n",
    "    def forward(self, edge_index, edge_label_index=None):\n",
    "        out = self.get_embedding(edge_index)\n",
    "        \n",
    "        out_src = out[edge_label_index[0]]\n",
    "        out_dst = out[edge_label_index[1]]\n",
    "        #Eq.5 in the LightGCN paper https://arxiv.org/pdf/2002.02126\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.n_nodes}, '\n",
    "                f'{self.embedding_dim}, num_layers={self.K})')\n",
    "\n",
    "    def recommendation_loss(\n",
    "        self,\n",
    "        pos_edge_rank,\n",
    "        neg_edge_rank,\n",
    "        node_id,\n",
    "        lambda_reg = 1e-4,\n",
    "    ):\n",
    "        r\"\"\"The Bayesian Personalized Ranking (BPR) loss.\n",
    "        \n",
    "        The BPR loss is a pairwise loss that encourages the prediction of an\n",
    "        observed entry to be higher than its unobserved counterparts\n",
    "        (see `here <https://arxiv.org/abs/2002.02126>`__).\n",
    "        \"\"\"\n",
    "        import torch.nn.functional as F\n",
    "        log_prob = F.logsigmoid(pos_edge_rank - neg_edge_rank).mean()\n",
    "        emb = self.node_emb.weight[node_id]\n",
    "        regularization = lambda_reg * emb.norm(p=2).pow(2)\n",
    "        regularization = regularization / pos_edge_rank.size(0)\n",
    "        return -log_prob + regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd3d55-930c-4736-a0a5-7f4311c533f1",
   "metadata": {},
   "source": [
    "## Trainning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcd255-d0ac-4a9c-aa13-4c826f15e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    user_pos_items = {}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        user_pos_items[user].append(item)\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030a2ff-52c3-4cb6-8dba-1daa4f284142",
   "metadata": {},
   "source": [
    "## Question: Explain what is the NDCG and how does it compare with with Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fc21d-51f1-41d1-8e07-d75cc2039a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCGAtK(groundTruth, pred, k):\n",
    "    \"\"\"\n",
    "    https://towardsdatascience.com/demystifying-ndcg-bee3be58cfe0\n",
    "    \"\"\"\n",
    "    max_r = torch.zeros(k)\n",
    "    length = min(len(groundTruth), k)\n",
    "    max_r[:length] = 1\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    idcg\n",
    "    r = []\n",
    "    for item in pred:\n",
    "        if item in groundTruth:\n",
    "            r.append(1)\n",
    "        else:\n",
    "            r.append(0)\n",
    "    dcg = torch.sum(torch.tensor(r) * 1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    return dcg/idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49ead-9988-4294-91f6-39ff6c0ca2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer, model, train_edge_index, train_edge_label_index, num_user, num_movie, batch_size):\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    device = torch.device('cpu')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        range(train_edge_label_index.size(1)),\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    for index in tqdm(train_loader):\n",
    "        pos_edge_label_index = train_edge_label_index[:, index]\n",
    "        \n",
    "        neg_edge_label_index = torch.stack([\n",
    "                pos_edge_label_index[0],\n",
    "                torch.randint(num_user, num_user + num_movie,\n",
    "                              (index.numel(), ), device=device)\n",
    "            ], dim=0)\n",
    "        \n",
    "        edge_label_index = torch.cat([\n",
    "                pos_edge_label_index,\n",
    "                neg_edge_label_index,\n",
    "            ], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pos_rank, neg_rank = model(train_edge_index, edge_label_index).chunk(2)\n",
    "        loss = model.recommendation_loss(\n",
    "                pos_rank,\n",
    "                neg_rank,\n",
    "                node_id=edge_label_index.unique(),\n",
    "            )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pos_rank.numel()\n",
    "        total_examples += pos_rank.numel()\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f2314-d3b5-4239-a2bd-ccdf59d27204",
   "metadata": {},
   "source": [
    "## Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de603f14-3e36-47ad-9d4a-9c2fb9bd1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, train_data_homo_edge_index, train_edge_label_index, test_edge_label_index, num_user, num_movie, k=20):\n",
    "    # fetch the embedding with the full train graph on homogenous graph \n",
    "    emb = model.get_embedding(train_data_homo_edge_index)\n",
    "    user_emb, movie_emb = emb[:num_user], emb[num_user:]\n",
    "    logits = user_emb @ movie_emb.t()\n",
    "    \n",
    "    v = torch.tensor([1]*train_edge_label_index.size(1))\n",
    "    mask = torch.sparse_coo_tensor(train_edge_label_index, v, (num_user, num_movie)).bool().to_dense()\n",
    "    logits[mask] = float('-inf')\n",
    "    \n",
    "    pred = logits.topk(k=k).indices\n",
    "    groundTruth = get_user_positive_items(test_edge_label_index)\n",
    "    \n",
    "    ndcg = precision = recall = total_examples = 0\n",
    "    for elem in groundTruth.keys():\n",
    "        total_examples += 1\n",
    "        num_elem = len(groundTruth[elem])\n",
    "        predSet = set(pred[elem].tolist())\n",
    "        groundTruthSet = set(groundTruth[elem])\n",
    "        intersection = groundTruthSet.intersection(predSet)\n",
    "        ndcg += NDCGAtK(groundTruth[elem], pred[elem], k)\n",
    "        recall += len(intersection)/num_elem\n",
    "        precision += len(intersection)/k\n",
    "    \n",
    "    return recall/total_examples, precision/total_examples, ndcg/total_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0a560-b52a-40d7-a85e-3f6e2960bb72",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4641b-ffdd-42ff-9689-75fa953babab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    run = wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"LightGCN\",\n",
    "        config=config\n",
    "    )\n",
    "    transform = RandomLinkSplit(\n",
    "        num_val=0.0,\n",
    "        num_test=config[\"test_split\"],\n",
    "        neg_sampling_ratio=0.0,\n",
    "        is_undirected=True,\n",
    "        edge_types=[('user', 'rates', 'movie')],\n",
    "        rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    "    )\n",
    "    \n",
    "    device = torch.device('cpu')\n",
    "    dataset = MovieLensSmall('./data')\n",
    "    full_data = dataset[0]\n",
    "    train_data, _, test_data = transform(full_data)\n",
    "    train_data_homo = train_data.to_homogeneous()\n",
    "    num_user, num_movie = full_data['user'].num_nodes, full_data['movie'].num_nodes\n",
    "    train_edge_label_index = train_data['user', 'rates', 'movie'].edge_label_index\n",
    "    test_edge_label_index = test_data['user', 'rates', 'movie'].edge_label_index\n",
    "    train_data_homo_edge_index = train_data_homo.edge_index\n",
    "    train_data_homo_edge_label_index = train_data_homo.edge_label_index\n",
    "    \n",
    "    model = LightGCN(\n",
    "        num_nodes=num_user+num_movie,\n",
    "        embedding_dim=config[\"latent_dim\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    for epoch in range(config[\"num_epoch\"]):\n",
    "        loss = train(optimizer, model, train_data_homo_edge_index, train_data_homo_edge_label_index, num_user, num_movie, config[\"batch_size\"])\n",
    "        recall, precision, ndcg = test(model, train_data_homo_edge_index, train_edge_label_index, test_edge_label_index, num_user, num_movie, k=20)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Recall@20: {recall:.4f}, Precision@20: {precision:.4f}, Ndcg@K: {ndcg:.4f}')\n",
    "        wandb.log({\"Loss\": loss, \"Recall@20\": recall,  \"Precision@20\":precision, \"Ndcg@K\":ndcg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e7fc3e-b8ec-4f7a-af0f-5ced2a90e997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "config = {\n",
    "    \"batch_size\": 1024,\n",
    "    \"num_epoch\": 50,\n",
    "    \"lr\": 0.005,\n",
    "    \"latent_dim\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"test_split\": 0.3,\n",
    "}\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d7bb0-4c7e-4827-aaab-629043593ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

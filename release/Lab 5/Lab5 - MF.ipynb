{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee8a7df1",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/1/1d/Logo_T%C3%A9l%C3%A9com_SudParis.svg/1014px-Logo_T%C3%A9l%C3%A9com_SudParis.svg.png\" width=\"10%\" />\n",
    "</center>\n",
    "\n",
    "<center> <h2> NET 4103/7431 Complex Network </h2> </center>\n",
    "\n",
    "<center> <h3> Vincent Gauthier (vincent.gauthier@telecom-sudparis.eu) </h3> </center>\n",
    "\n",
    "### Note\n",
    "Avant de commencer les exercices, assurez-vous que tout fonctionne comme prévu. Tout d'abord, le redémarrage du kernel **(dans la barre de menus, sélectionnez le kernel $\\rightarrow$ Restart)**.\n",
    "\n",
    "Assurez-vous que vous remplir les célluler aux endroits marquer «YOUR CODE HERE». \n",
    "\n",
    "Veuillez supprimer les ligne «raise NotImplementedError()» dans toutes les cellules auxquelles vous avez répondu, ainsi que votre nom et prénom ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742558a4",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NOM = \"XXX\"\n",
    "PRENOM = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87647c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be57b9e-8953-4cf8-aa6d-70bc581298ec",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lab #5: Building Recommander System (RecSys) With Neural Matrix Factorization</h1> \n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<img src=\"../../images/network.png\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9963b6-9a93-4902-82eb-93f9eb1f729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Style pour le Notebook\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c349c-133e-43cf-9e23-2ff0fa5a2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from packaging import version\n",
    "import sys \n",
    "import torch\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"networkx version:\", nx.__version__)\n",
    "print(\"torch versions:\", torch.__version__)\n",
    "\n",
    "# assert networkx version is greater or equal to 3.0\n",
    "assert version.parse(nx.__version__) >= version.parse(\"3.0\")\n",
    "assert version.parse(torch.__version__) >= version.parse(\"2.0\")\n",
    "# assert python version is greater that 3.9\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 9  \n",
    "\n",
    "# If working in colab mount the drive filesystem \n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Working in colab')\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"working locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46875c1f-105f-4451-938c-420925fe3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import wandb\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca818d-2077-4f47-967c-5aa72d63e331",
   "metadata": {},
   "source": [
    "### Download and Parse the MovieLen Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2ff68-e229-4c28-81dc-4a7a8da2bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLenSmall(Dataset):\n",
    "    def __init__(self, root=\"./data\"):\n",
    "        # Setup path to data folder\n",
    "        self.root_path = Path(root)\n",
    "        self.url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "        self.download()\n",
    "        self.process()\n",
    "        self.data = torch.load(self.processed_path / \"movielen.pt\")\n",
    "        self.enc_movie = dict()\n",
    "        self.enc_user = dict()\n",
    "        \n",
    "    @property\n",
    "    def raw_path(self):\n",
    "        return self.root_path / \"raw\"\n",
    "\n",
    "    @property\n",
    "    def processed_path(self):\n",
    "        return self.root_path / \"processed\"\n",
    "\n",
    "    def download(self):\n",
    "        # If the image folder doesn't exist, download it and prepare it... \n",
    "        if not self.raw_path.is_dir():\n",
    "            print(f\"Did not find {self.raw_path} directory, creating one...\")\n",
    "            self.raw_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "            # Download \n",
    "            with open(self.raw_path / \"ml-latest-small.zip\", \"wb\") as f:\n",
    "                request = requests.get(self.url)\n",
    "                print(\"Downloading...\")\n",
    "                f.write(request.content)\n",
    "    \n",
    "            # Unzip \n",
    "            with zipfile.ZipFile(self.raw_path /  \"ml-latest-small.zip\", \"r\") as zip_ref:\n",
    "                print(\"Unzipping...\") \n",
    "                zip_ref.extractall(self.raw_path)\n",
    "\n",
    "    def process(self):\n",
    "        if not self.processed_path.is_dir():\n",
    "            data = Data()\n",
    "            # If the image processed_path doesn't exist, prepare it... \n",
    "            print(f\"Did not find {self.processed_path} directory, creating one...\")\n",
    "            self.processed_path.mkdir(parents=True, exist_ok=True)\n",
    "            file = self.raw_path / \"ml-latest-small\" / \"ratings.csv\"\n",
    "            rating = pd.read_csv(file)\n",
    "            file = self.raw_path / \"ml-latest-small\" / \"movies.csv\"\n",
    "            movie = pd.read_csv(file)\n",
    "            df, num_user, num_movie, num_sample = self.parse_ratings(rating, movie)\n",
    "            data.num_user = num_user\n",
    "            data.num_movie = num_movie\n",
    "            data.num_sample = num_sample\n",
    "            data.user = torch.from_numpy(df.userId.values).long()\n",
    "            data.movie = torch.from_numpy(df.movieId.values).long()\n",
    "            data.rating = torch.from_numpy(df.rating.values).float()\n",
    "            data.title = df.title.values\n",
    "            data.genres = df.genres.values\n",
    "            \n",
    "            torch.save(data, self.processed_path / \"movielen.pt\")\n",
    "\n",
    "    def parse_ratings(self, rating, movie):\n",
    "        # merge \n",
    "        df = pd.merge(rating, movie, on=\"movieId\")\n",
    "        # Normalize ratings\n",
    "        df.drop(\"timestamp\", axis=1, inplace=True)\n",
    "        rating, min_rating, max_rating = df[\"rating\"], df[\"rating\"].min(), df[\"rating\"].max()\n",
    "        # minmax scaler\n",
    "        df[\"rating\"] = (df.rating - min_rating) / (max_rating - min_rating)\n",
    "        # save the real ratings\n",
    "        df[\"rating_rel\"] = df[\"rating\"]\n",
    "        \n",
    "        # Do not recommend if the rating is less than 0.5\n",
    "        cond = df[\"rating\"] < 0.5\n",
    "        df[\"rating\"].where(cond, 0, inplace=True)\n",
    "        df[\"rating\"].where(~cond, 1, inplace=True)\n",
    "    \n",
    "        # Encode userId and movieId\n",
    "        self.enc_movie = {movieId:idx for idx, movieId in enumerate(pd.unique(df.movieId))}\n",
    "        df[\"movieId\"] = [self.enc_movie[movieId] for movieId in df.movieId]\n",
    "        self.enc_user = {userId:idx for idx, userId in enumerate(pd.unique(df.userId))}\n",
    "        df[\"userId\"] = [self.enc_user[userId] for userId in df.userId]\n",
    "        \n",
    "        return df, len(self.enc_user), len(self.enc_movie), len(df)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.num_sample\n",
    "\n",
    "    @property\n",
    "    def num_movie(self):\n",
    "        return self.data.num_movie\n",
    "\n",
    "    @property\n",
    "    def num_user(self):\n",
    "        return self.data.num_user\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"user\": self.data.user[idx], \n",
    "            \"movie\": self.data.movie[idx], \n",
    "            \"rating\": self.data.rating[idx], \n",
    "            \"title\": self.data.title[idx],\n",
    "            \"genres\": self.data.genres[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d3089-e1e9-4a76-9700-24505ee2c157",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de677dc-d73d-4f4a-a68b-f1c0ce9280bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movielen_dataset = MovieLenSmall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317dd030-dcdb-4646-9fad-22b5a056f378",
   "metadata": {},
   "source": [
    "## Question 1: Plot the distribution of the number of recommandation per movie\n",
    "\n",
    "### What can you conclude about the distribution ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17826330-07a1-4aa3-9c52-48cd3391dad7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1aa01895d0ca78d8a5be0e6b6eb847e3",
     "grade": true,
     "grade_id": "cell-d4d5658d628a9c6a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "ax.loglog(edges[:-1], counts, 'o')\n",
    "ax.set_xlabel(\"# of review\")\n",
    "ax.set_ylabel(\"PDF\");\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c2951-84df-43f1-a5d7-099061642fd9",
   "metadata": {},
   "source": [
    "## What is the distribution of the movies ratings ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e13e21-eae1-4b7e-a1c2-ff30e25c75b3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c869f4841b01e33c52cae573a484f066",
     "grade": true,
     "grade_id": "cell-3f7f4c25e216d9f4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce80b75-2e3a-4c82-93ad-6e8367b1645e",
   "metadata": {},
   "source": [
    "## The model: The Generalized Matrix Factorization model\n",
    "\n",
    "We search here what are the embeddings such as the product of the items embedding and the user embedding \n",
    "- fill out the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907993e9-dddd-4f99-98d1-144abc244430",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80959c3123c7cb7f51e4da9555b1f2d",
     "grade": true,
     "grade_id": "cell-47f0d93e318d6795",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Question for student add bias to the user and movie embeddings\n",
    "# Look for Lecture 3 Part B Matrix Factorization with PyTorch https://www.youtube.com/watch?v=LJX5hdw-zUI&ab_channel=YannetInterian\n",
    "\n",
    "class MF(nn.Module):\n",
    "    \"\"\"The Generalized Matrix Factorization model.\"\"\"\n",
    "    def __init__(self, num_user, num_movie, emb_size):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_user, emb_size)\n",
    "        self.movie_emb = nn.Embedding(num_movie, emb_size)\n",
    "        self.affine_tranform = nn.Linear(in_features=emb_size, out_features=1)\n",
    "        self.reset_params()\n",
    "        \n",
    "\n",
    "    def reset_params(self):\n",
    "        self.user_emb.weight.data.uniform_(0.5, 1.0)\n",
    "        self.movie_emb.weight.data.uniform_(0.5, 1.0)\n",
    "    \n",
    "    def forward(self, u, v):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb777ecf-3483-4ef2-9a5c-abfb89c95cd1",
   "metadata": {},
   "source": [
    "## Train and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf24d5-4605-4a87-a2f4-ca195e89040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for gpu\n",
    "def check_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        # for mac os GPU (Apple silicon)\n",
    "       return torch.device(\"mps\")\n",
    "    elif torch.backends.cuda.is_available():\n",
    "        # for cuda device \n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926a303-de91-4af8-8dc1-d467ec5ac8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, lr, wd, epochs, batch_size, device, log_idx=100, best_model_path='best-model-parameters.pt'):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    # Why did we choose the BCE loss\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    batchs = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    best_loss = 1.0\n",
    "    \n",
    "    model.train()\n",
    "    print(\"Start trainning...\")\n",
    "    pbar = tqdm.tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        running_loss = 0.0\n",
    "        for idx, batch in enumerate(batchs):\n",
    "            R_hat = model(batch[\"user\"].to(device), batch[\"movie\"].to(device)).reshape(-1)\n",
    "            loss = criterion(R_hat, batch[\"rating\"].to(device))\n",
    "\n",
    "            # Compute the RMSE here \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # accumulate loss and log\n",
    "            running_loss += loss.item()\n",
    "            if idx % log_idx == log_idx - 1:\n",
    "                if (running_loss / log_idx) < best_loss:\n",
    "                    best_loss = (running_loss / log_idx)\n",
    "                    # Save best model \n",
    "                    save_model(model, best_model_path) \n",
    "                message = f\"[{epoch}:{idx + 1}] {running_loss / log_idx:.3f}\"\n",
    "                wandb.log({\"train/loss\": running_loss / log_idx})\n",
    "                pbar.set_description(message)\n",
    "                pbar.refresh() # to show immediately the update\n",
    "                running_loss = 0.0\n",
    "\n",
    "def save_model(model, best_model_path):\n",
    "    # official recommended\n",
    "    root = Path(\"./saved_models\")\n",
    "    if not root.is_dir():\n",
    "        root.mkdir()\n",
    "    torch.save(model.state_dict(), root / best_model_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185617e-a370-4025-b5c4-fb96d1c4e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, best_model_path, validation_data, device):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # Setup the model with the best weights \n",
    "    path = Path(\"./saved_models\")\n",
    "    model.load_state_dict(torch.load(path / best_model_path))\n",
    "    model.to(device)\n",
    "    # Evaluate \n",
    "    model.eval()\n",
    "    data = validation_data[0:-1]\n",
    "    R_hat = model(data[\"user\"].to(device), data[\"movie\"].to(device)).reshape(-1)\n",
    "    loss = criterion(R_hat, data[\"rating\"].to(device))\n",
    "    # Logs\n",
    "    print(f'Valiation Loss: {loss.item() / len(validation_data)}')\n",
    "    wandb.log({\"validation/loss\": loss.item() / len(validation_data)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293547c-3ead-4025-bae7-1213f3fc76c4",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923331f7-a1e0-4549-8b35-3866a6ac80d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "dataset = MovieLenSmall()\n",
    "device = check_device()\n",
    "print(f'device: {device}')\n",
    "\n",
    "train_len = int(0.8*len(dataset))\n",
    "valid_len = len(dataset) - train_len\n",
    "train_data = torch.utils.data.Subset(dataset, range(train_len))\n",
    "val_data = torch.utils.data.Subset(dataset, range(train_len, len(dataset)))\n",
    "\n",
    "#train_data, val_data = random_split(dataset, [train_len, valid_len])\n",
    "\n",
    "epochs = 45\n",
    "lr = 5e-4\n",
    "wd = 1e-4\n",
    "batch_size = 10\n",
    "emb_size = 100\n",
    "best_model_path = \"MF-parameters.pt\"\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"Matrix Factorization\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\":batch_size,\n",
    "        \"embedding_size\": emb_size,\n",
    "        \"weight_decay\": wd,\n",
    "    },\n",
    ")\n",
    "\n",
    "model = MF(dataset.num_user, dataset.num_movie, emb_size).to(device)\n",
    "train(model, train_data, lr, wd, epochs, batch_size=batch_size, device=device, log_idx=1000, best_model_path=best_model_path)\n",
    "validation(model, best_model_path, val_data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8f470-7f59-410e-ba71-c610aa4077c4",
   "metadata": {},
   "source": [
    "#### [show example of loss function](https://wandb.ai/vgauthier/Matrix%20Factorization/reports/train-loss-24-07-22-20-49-22---Vmlldzo4NzY4MDM0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc07a94-e77e-4184-b1ea-9e6c70495b76",
   "metadata": {},
   "source": [
    "## Question: Compute Recal@k and Precision@k \n",
    "\n",
    "* [Building Recommender System with PyTorch using Collaborative Filtering](https://www.youtube.com/watch?v=Wj-nkk7dFS8&ab_channel=AIAlchemy)\n",
    "\n",
    "* https://surprise.readthedocs.io/en/latest/FAQ.html#how-to-compute-precision-k-and-recall-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837fa2b-b047-47b5-a15b-e451e2da8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "best_model_path = \"saved_models/MF-parameters.pt\"\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 10\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "user_est_true = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(val_loader):\n",
    "        users = batch[\"user\"]\n",
    "        movies = batch[\"movie\"]\n",
    "        ratings = batch[\"rating\"]\n",
    "        pred = model(batch[\"user\"].to(device), batch[\"movie\"].to(device)).reshape(-1).sigmoid()\n",
    "        \n",
    "        for i in range(len(users)):\n",
    "            user_id = users[i].item()\n",
    "            movie_id = movies[i].item()\n",
    "            pred_rating = pred[i].item()\n",
    "            true_rating = ratings[i].item()\n",
    "            user_est_true[user_id].append((pred_rating, true_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229038cd-4218-4aa1-9746-964d5e377c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "k = 10\n",
    "good_user = dict()\n",
    "for uid, user_ratings in user_est_true.items():\n",
    "    n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "    if n_rel >= k:\n",
    "        good_user[uid] = user_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73895498-bcdb-4e43-b9da-dcf9841084f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=0.75):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in predictions.items():\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "        #print(uid, n_rel_and_rec_k)\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090f46c-c09b-4606-b46d-878529a3ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls = precision_recall_at_k(good_user, threshold=0.8, k=10)\n",
    "\n",
    "# Precision and recall can then be averaged over all users\n",
    "print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "print(sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972672e1-1c16-4a3a-8987-d068718947d3",
   "metadata": {},
   "source": [
    "## Question: Add parameters to the model to the model such as:\n",
    "\n",
    "- a parameter for the mean user rating\n",
    "- a parameter for the mean item rating\n",
    "- mean rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e4b0b-3531-4f4a-b5f1-002d158b0e73",
   "metadata": {},
   "source": [
    "## Question: Use a optimizer to fine tune the model hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747be835-bc78-4f3e-aab2-6f779b23f7d6",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "1. [Recommender Systems: Generalized Matrix Factorization from Scratch](https://www.youtube.com/watch?v=gZgftF5hZOs&ab_channel=DavidOniani)\n",
    "2. [The Generalized Matrix Factorization model](https://github.com/oniani/ai/blob/main/model/dl/gmf.py)\n",
    "3. [cours CNAM](https://cedric.cnam.fr/vertigo/Cours/RCP216/coursSimilariteRecommandation.html#systemes-de-recommandation)\n",
    "4. [Google Notes on Matrix Factorization](https://developers.google.com/machine-learning/recommendation/collaborative/matrix?hl=fr)\n",
    "5. [Mining Massive Dataset Stanford University (webpage)](https://web.stanford.edu/class/cs246/)\n",
    "6. [Mining Massive Dataset Stanford University (youtube)](https://www.youtube.com/watch?v=xoA5v9AO7S0&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV&ab_channel=ArtificialIntelligence-AllinOne)\n",
    "7. [Recommendation Systems — A walk through](https://chaitanyabelhekar.medium.com/recommendation-systems-a-walk-trough-33587fecc195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d94ad-75b2-4003-89a5-4c612dd75fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/fr/thumb/1/1d/Logo_T%C3%A9l%C3%A9com_SudParis.svg/1014px-Logo_T%C3%A9l%C3%A9com_SudParis.svg.png\" width=\"10%\" />\n",
    "</center>\n",
    "\n",
    "<center> <h2> NET 4103/7431 Complex Network </h2> </center>\n",
    "\n",
    "<center> <h3> Vincent Gauthier (vincent.gauthier@telecom-sudparis.eu) </h3> </center>\n",
    "\n",
    "### Note\n",
    "Avant de commencer les exercices, assurez-vous que tout fonctionne comme prévu. Tout d'abord, le redémarrage du kernel **(dans la barre de menus, sélectionnez le kernel $\\rightarrow$ Restart)**.\n",
    "\n",
    "Assurez-vous que vous remplir les célluler aux endroits marquer «YOUR CODE HERE». \n",
    "\n",
    "Veuillez supprimer les ligne «raise NotImplementedError()» dans toutes les cellules auxquelles vous avez répondu, ainsi que votre nom et prénom ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "NOM = \"XXX\"\n",
    "PRENOM = \"XXX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lab #2: PageRank</h1> \n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<img src=\"../../images/network.png\" style=\"display:block;margin-left:auto;margin-right:auto;width:80%;\"></img>\n",
    "\n",
    "# Anglais\n",
    "## Introduction\n",
    "\n",
    "Before 1998, the web graph was a largely unused source of information and ignored by search engines such as Yahoo, or Astalavista. However, researchers such as Jon Kleinberg [2] and Brin and Page [3] have used this resource to create an algorithmically elegant methodology that has helped develop the search engines we know today. They then mainly used the following idea: a hyperlink link from my web page to another page can be interpreted as a recommendation from me to the web page in question. The underlying idea that is exploited is the following: a web page that is quoted very often must have a better ranking than a less frequently cited web page. However, this idea is not new, but used as the sole selective criterion is not enough. For example, a letter of recommendation for a job from the CEO of Orange will surely carry more weight than the other 10 letters of recommendation that you could have received from random people. In conclusion, the importance of the recommendations (and not only their numbers) must also be taken into account in calculating the reputation of a web page. This is exactly the principle of **PageRank**.\n",
    "\n",
    "In current search engines, each indexed webpage is associated with a \"**PageRank**\" value. When you perform a search, the search engine returns the web pages corresponding to the keywords sorted in ascending order of their value of \"PageRank\". The underlying assumption that is used is that: the web page with the highest \"PageRank\" value must be the most relevant for the keywords considered.\n",
    "\n",
    "In short, the notoriety (PageRank value) of a web page is defined as follows: the reputation of a web page is important, if it is itself pointed by other web pages with significant notoriety. This circular reasoning is at the heart of the algorithm that will be developed during this exercise. Through this circular reasoning, we deduce that the values of PageRank are in fact the values of the stationary states of an immense Markov chain. The transitions of this Markov chain are defined by the web graph. The matrix of transitions of this Markov chain is called \"Google\" matrix $\\mathbf{G}$. In order to calculate this stationary state vector, however, the Markov chain in question must have a unique solution. For this, one of the conditions is that the transitions graph must be irreducible (ie the graph forms a connected component), which is not the case for the web graph (cf. Fig. 1). The PageRank algorithm allowed Brin and Page to intelligently bypass this difficulty applying a transformation on the adjacency matrix in order to assume the irreducibility of this one.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/Scc.png\" width=\"500px\"></img>\n",
    "<div align=\"center\"><b>Fig. 1</b></div>\n",
    "</div>\n",
    "\n",
    "**PageRank's Algorithm**\n",
    "1. Normalization of the adjacency matrix of the web graph to generate a stochastic matrix\n",
    "2. we update the matrix from the previous step in order to take into account the Dangling nodes (the node that don't have any outgoing link)\n",
    "3. Create the \"Google\" Matrix\n",
    "4. Compute the stationary state of the Markov chain\n",
    "\n",
    "In the first part of this exiercice we are going to considere the follwing directed graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (cf. **Fig. 2**), as small example of the web graph. Each edge $e \\in \\mathcal{E}$ represente one hyperlink from one webpage $v \\in \\mathcal{V}$ to another.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/GraphPageRank.png\" width=\"400px\"></img>\n",
    "<div align=\"center\"><b>Fig. 2</b></div>\n",
    "</div>\n",
    "\n",
    "### Notations\n",
    "$\\mathbf{A}$: The adjacency matrix of the graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$\n",
    "\n",
    "$\\mathbf{H}$: Normalized adjacency matrix\n",
    "\n",
    "$\\mathbf{G}$: The dense, stochastic matrix called teh \"Google\" matrix\n",
    "\n",
    "$\\mathbf{\\pi}^T$: PageRank Vector, a stationnay vector of the Markov chain describe by the matrix $\\mathbf{G}$\n",
    "\n",
    "$n$ : Number of the web page (in our graph)\n",
    "\n",
    "$\\alpha$: parameter between 0 and 1\n",
    "\n",
    "### Conventions\n",
    "\n",
    "$\\mathbf{e}^T$ : is vector line $\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}$\n",
    "\n",
    "$\\mathbf{e}$ : is a vector colomn  $\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$\n",
    "\n",
    "$\\sigma(\\mathbf{A})$ est l'ensemble (set) des valeurs propres de la matrice $\\mathbf{A}$\n",
    "\n",
    "$\\lambda_{max} = \\max_{\\lambda \\in \\sigma(\\mathbf{A})} \\lvert \\lambda \\lvert$ est la plus grande valeur propre de la matrice $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{e} \\otimes \\mathbf{e}^T$ : est le produit exterieur $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3  \\end{pmatrix}  \\otimes \\begin{pmatrix} 1 & 2 & 3 \\end{pmatrix} = \\begin{pmatrix} 1 & 2 & 3  \\\\ 2 & 4 & 6 \\\\ 3 & 6 & 9 \\end{pmatrix}$\n",
    "\n",
    "### Python Reminder \n",
    "Multiplication and division with Numpy:\n",
    "```Python\n",
    "import numpy as np\n",
    "x = np.array([2, 2, 2])\n",
    "2*x\n",
    ">>> array([4, 4, 4])\n",
    "x = np.array([2, 2, 2])\n",
    "x/2\n",
    ">>> array([1, 1, 1])\n",
    "A = np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]])\n",
    "A/2\n",
    ">>> np.array([[1, 1, 1], \n",
    "              [1, 1, 1], \n",
    "              [1, 1, 1]])\n",
    "```\n",
    "\n",
    "Matrix vector division:\n",
    "```Python\n",
    "A = np.array([[1, 1], [4, 4]])\n",
    "b = np.array([1, 3])\n",
    "(A.T/b).T\n",
    ">>> array([[ 1.        ,  1.        ],\n",
    "           [ 1.33333333,  1.33333333]])\n",
    "```\n",
    "\n",
    "Dot product:\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 2, 2], [2, 2, 2]])\n",
    "x = np.array([2, 2, 2])\n",
    "np.dot(A,x)\n",
    ">>> array([12, 12])\n",
    "\n",
    "a = np.array([1, 1, 1])\n",
    "b = np.array([1, 1, 1])\n",
    "np.outer(a,b)\n",
    ">>> array([[1, 1, 1], \n",
    "           [1, 1, 1], \n",
    "           [1, 1, 1]])\n",
    "```\n",
    "\n",
    "Matrix transpose:\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "A.T\n",
    ">>> array([[1, 3],\n",
    "           [2, 4]])\n",
    "```\n",
    "\n",
    "Shape of a matrix\n",
    "```Python\n",
    "A = np.array([[1, 1, 1], [1, 1, 1]])\n",
    "n, m = A.shape\n",
    "print(n, m)\n",
    ">>> 2 3\n",
    "```\n",
    "\n",
    "Sum of each row entries of a matrix\n",
    "```Python\n",
    "A = np.array([[1, 1, 1,], [2, 2, 2]])\n",
    "A[1,:].sum()\n",
    ">>> 6\n",
    "```\n",
    "\n",
    "# Français\n",
    "## Introduction \n",
    "\n",
    "Avant 1998, le graphe du web était une source d'information largement inutilisée et ignorée par les moteurs de recherche tels que Yahoo, ou Astalavista. Cependant, des chercheurs tels que Jon Kleinberg [2] et Brin et Page [3] ont utilisé cette ressource afin de créer une méthodologie algorithmiquement élégante qui a permis de développer les moteurs de recherche que l'on connait aujourd'hui. Ils ont alors principalement utilisé l'idée suivante: un lien hyperlink de ma page web vers une autre page peut être interprété comme une recommandation de ma part vers la page web en question. L’idée sous-jacente qui est exploitée est la suivante: une page web qui est citée très souvent doit être une page web plus importante que page web moins souvent citée. Cependant, cette idée n'est pas nouvelle, utiliser la bibliometrie (le nombre de citations) comme unique critère sélectif n’est pas suffisant. Par exemple, une lettre de recommandation pour un travail provenant du PDG d’orange aura surement plus de poids que les 10 autres lettres  de recommandation que vous auriez pu avoir. En conclusion, l’importance des recommandations (et non pas seulement leurs nombres) doit aussi être prise en compte dans le calcul de la notoriété d’une page web. C’est exactement le principe du **PageRank**.\n",
    "\n",
    "Dans les moteurs de recherche actuels, on associe à chaque page web indexée une valeur de \"PageRank\". Lorsque vous effectuez une recherche, le moteur de recherche vous retourne les pages web correspondant aux mots clés triés par ordre croissant de leur valeur de \"PageRank\". L’hypothèse sous-jacente qui est utilisée est que: la page web qui possède la valeur de \"PageRank\" la plus élevée doit être la plus pertinente pour les mots clés considérés. \n",
    "\n",
    "Afin de faire court, la notoriété (valeur du PageRank) d'une page web est définie comme suit: la notoriété d’une page web est importante, si elle est elle-même pointée par d’autres pages web avec une notoriété importante. Ce raisonnement circulaire est au coeur de l'algorithme qui va être développé durant cet exercice. Au travers de ce raisonnement circulaire, on en déduit que les valeurs de PageRank  sont en fait les valeurs des états stationnaires d'une immense chaîne de Markov. Les transitions de cette chaîne de Markov sont définies par le graphe du web. La matrice des transitions de cette chaîne de Markov est appelée \"Google\" matrice $\\mathbf{G}$. Afin de calculer ce vecteur d'états stationnaires, il faut cependant que la chaîne de Markov en question admette une solution unique. Pour cela, une des conditions est: qu’il faut que le graphe des transitions soit irréductible (c.-à-d. que le graphe forme une composante connexe) ce qui n'est pas le cas du graphe du web (cf. Fig. 1). L'algorithme du PageRank a permis a Brin et Page de contourner intelligemment cette difficulter appliquant une transformation sur la matrice d’adjacence afin de s’assumer de l’irréductibilité de celle-ci.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/Scc.png\" width=\"500px\"></img>\n",
    "<b>Figure 1</b>\n",
    "</div>\n",
    "\n",
    "**Algorithme du PageRank**\n",
    "1. Normalisation de la matrice d'adjacence du graphe du web\n",
    "2. Découverte des noeuds du graphe du web ne possédant pas de lien de sortie (aucun lien hypertext)\n",
    "3. Création de la \"Google\" Matrice \n",
    "4. Calcul de la valeur des états stationnaires de la chaîne de Markov  \n",
    "\n",
    "Dans la première partie de cet exercice nous allons considérer le graphe orienté suivant $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (cf. **Fig. 2**), comme un petit exemple du graphe du web. Chaque arc $e \\in \\mathcal{E}$ représente un lien hyperlink d'une page web $v \\in \\mathcal{V}$ (un noeud du graphe ) vers une autre.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/GraphPageRank.png\" width=\"400px\"></img>\n",
    "<b>Figure 2</b>\n",
    "</div>\n",
    "\n",
    "### Notations\n",
    "$\\mathbf{A}$: Matrice d'ajacence du graphe $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$\n",
    "\n",
    "$\\mathbf{H}$: Matrice d'adjacence normalisée\n",
    "\n",
    "$\\mathbf{G}$: Matrice dense, stochastique et complete appelée Google matrice \n",
    "\n",
    "$\\mathbf{\\pi}^T$: Vecteur ligne, stationnaire, appelé vecteur PageRank  \n",
    "\n",
    "$n$ : nombre de pages web dans le moteur de recherche\n",
    "\n",
    "$\\alpha$: paramétre entre 0 et 1\n",
    "\n",
    "### Conventions\n",
    "\n",
    "$\\mathbf{e}^T$ : est une vecteur ligne $\\begin{pmatrix} 1 & 1 & 1 & 1 \\end{pmatrix}$\n",
    "\n",
    "$\\mathbf{e}$ : est un vecteur colonne  $\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$\n",
    "\n",
    "$\\sigma(\\mathbf{A})$ est l'ensemble (set) des valeurs propres de la matrice $\\mathbf{A}$\n",
    "\n",
    "$\\lambda_{max} = \\max_{\\lambda \\in \\sigma(\\mathbf{A})} \\lvert \\lambda \\lvert$ est la plus grande valeur propre de la matrice $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{e} \\otimes \\mathbf{e}^T$ : est le produit exterieur $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3  \\end{pmatrix}  \\otimes \\begin{pmatrix} 1 & 2 & 3 \\end{pmatrix} = \\begin{pmatrix} 1 & 2 & 3  \\\\ 2 & 4 & 6 \\\\ 3 & 6 & 9 \\end{pmatrix}$\n",
    "\n",
    "### Rapels d'algébre vectoriel en python \n",
    "Multiplication et division terme à terme:\n",
    "```Python\n",
    "import numpy as np\n",
    "x = np.array([2, 2, 2])\n",
    "2*x\n",
    ">>> array([4, 4, 4])\n",
    "x = np.array([2, 2, 2])\n",
    "x/2\n",
    ">>> array([1, 1, 1])\n",
    "A = np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]])\n",
    "A/2\n",
    ">>> np.array([[1, 1, 1], \n",
    "              [1, 1, 1], \n",
    "              [1, 1, 1]])\n",
    "```\n",
    "\n",
    "Division d'une matrice par un vecteur \n",
    "```Python\n",
    "A = np.array([[1, 1], [4, 4]])\n",
    "b = np.array([1, 3])\n",
    "(A.T/b).T\n",
    ">>> array([[ 1.        ,  1.        ],\n",
    "           [ 1.33333333,  1.33333333]])\n",
    "```\n",
    "\n",
    "Produit vectoriel:\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 2, 2], [2, 2, 2]])\n",
    "x = np.array([2, 2, 2])\n",
    "np.dot(A,x)\n",
    ">>> array([12, 12])\n",
    "\n",
    "a = np.array([1, 1, 1])\n",
    "b = np.array([1, 1, 1])\n",
    "np.outer(a,b)\n",
    ">>> array([[1, 1, 1], \n",
    "           [1, 1, 1], \n",
    "           [1, 1, 1]])\n",
    "```\n",
    "\n",
    "Transposé:\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "A.T\n",
    ">>> array([[1, 3],\n",
    "           [2, 4]])\n",
    "```\n",
    "\n",
    "Dimention d'une matrice \n",
    "```Python\n",
    "A = np.array([[1, 1, 1], [1, 1, 1]])\n",
    "n, m = A.shape\n",
    "print(n, m)\n",
    ">>> 2 3\n",
    "```\n",
    "\n",
    "Somme d'une ligne d'une matrice\n",
    "```Python\n",
    "A = np.array([[1, 1, 1,], [2, 2, 2]])\n",
    "A[1,:].sum()\n",
    ">>> 6\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Style pour le Notebook\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from packaging import version\n",
    "import sys \n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"networkx version:\", nx.__version__)\n",
    "\n",
    "# assert networkx version is greater or equal to 2.6\n",
    "assert version.parse(nx.__version__) >= version.parse(\"2.6\")\n",
    "\n",
    "# assert python version is greater that 3.7\n",
    "assert sys.version_info[0] == 3\n",
    "assert sys.version_info[1] >= 7 \n",
    "\n",
    "# If working in colab mount the drive filesystem \n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Working in colab')\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"working locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Generate a synthetic web-graph with networkx\n",
    "\n",
    "With the help of networkx generate the directed graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (cf. **Fig 2**), and draw the graph with matplotlib in order to validate visualy that you obtain the same graph as in the **figure 2**. \n",
    "\n",
    "**Help**: Use the already defined functions in the networkx library to add vertices and edges to the graph ([networkx tutorial](https://networkx.github.io/documentation/networkx-1.10/tutorial/tutorial.html#nodes))\n",
    "\n",
    "# Français\n",
    "## Générer un graphe du web synthétique\n",
    "\n",
    "A l'aide de Networkx, générer le graphe orienté $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (cf. **Fig 2**), et dessiner le graphe à l'aide de matplotlib afin de valider visuellement s'il correspond bien à celui de la **figure 2**.\n",
    "\n",
    "**Aide**: on utilisera les methodes definie dans networkx pour ajouter des noeuds et des arc au graphe ([tutoriel networkx](https://networkx.github.io/documentation/networkx-1.10/tutorial/tutorial.html#nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce5deac44e9dcdf79565f93d9e750dac",
     "grade": false,
     "grade_id": "cell-b38b9e2b9a5a33ff",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "g = nx.DiGraph()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "pos = nx.spring_layout(g);\n",
    "nx.draw_networkx(g, pos=pos, node_size=600, font_size=20.0);\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff2b2087ce0fad434bdc059c5fc2b5c3",
     "grade": true,
     "grade_id": "cell-eb40bde129593b4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(g.nodes()) == 6\n",
    "assert g.has_edge(6,4)\n",
    "assert g.has_edge(4,6)\n",
    "assert g.has_edge(2,5) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Extract the adjacency matrix of a graph \n",
    "\n",
    "Before going further in the exercise, let's extract the adjacency matrix $\\mathbf{A}_{n \\times n}$ from the directed graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ to construct the normalized adjacency matrix of the $\\mathbf{H}_{n \\times n} $ graph.\n",
    "\n",
    "(eq. **1**)\n",
    "$$\n",
    "\\mathbf{H}_{ij} = \\begin{cases}\n",
    "    1/\\sum_{j} \\mathbf{A}_{ij} & \\text{ if there is a link between node } i \\text{ and } j\\\\\n",
    "    0 & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Exemple**: The matrix $\\mathbf{H}_{n \\times n}$ of the graph in figure 2.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\begin{pmatrix}\n",
    "  0 & 1/2 & 1/2 & 0 & 0 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "  1/3 & 1/3 & 0 & 0 & 1/3 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 1/2 & 1/2 \\\\\n",
    "  0 & 0 & 0 & 1/2 & 0 & 1/2 \\\\\n",
    "  0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Example: How to export the adjacency matrix from a networkx graph**\n",
    "```Python\n",
    ">>> import numpy as np\n",
    ">>> G = nx.Graph([(1,2), (2, 3)])\n",
    ">>> node_order = [1, 2, 3]\n",
    ">>> A = np.array(nx.adjacency_matrix(G, nodelist=node_order).todense())\n",
    ">>> A\n",
    "array([[0, 1, 0],\n",
    "       [1, 0, 1],\n",
    "       [0, 1, 0]])\n",
    "```\n",
    "\n",
    "\n",
    "# Français\n",
    "## Extraire la matrice d'adjacence du graphe\n",
    "\n",
    "Avant d'aller plus avant dans l'exercice, nous allons extraire la matrice d'adjacence $\\mathbf{A}_{n\\times n}$ du graphe dirigé $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$.  Celui-ci vous nous permettre de construire la matrice normalisés d'adjacence du graphe $\\mathbf{H}_{n\\times n}$.\n",
    "\n",
    "(eq. **1**)\n",
    "$$\n",
    "\\mathbf{H}_{ij} = \\begin{cases}\n",
    "    1/\\sum_{j} \\mathbf{A}_{ij} & \\text{ si il y a une lien entre le noeud } i \\text{ et } j\\\\\n",
    "    0 & \\text{ sinon}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Exemple**: La matrice $\\mathbf{H}_{n \\times n}$ correspondant au graphe defini dans la figure 1.\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\begin{pmatrix}\n",
    "  0 & 1/2 & 1/2 & 0 & 0 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "  1/3 & 1/3 & 0 & 0 & 1/3 & 0 \\\\\n",
    "  0 & 0 & 0 & 0 & 1/2 & 1/2 \\\\\n",
    "  0 & 0 & 0 & 1/2 & 0 & 1/2 \\\\\n",
    "  0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Example de recupération de la matrice d'ajacence avec networkx**\n",
    "```Python\n",
    ">>> import numpy as np\n",
    ">>> G = nx.Graph([(1,2), (2, 3)])\n",
    ">>> node_order = [1, 2, 3]\n",
    ">>> A = np.array(nx.adjacency_matrix(G, nodelist=node_order).todense())\n",
    ">>> A\n",
    "array([[0, 1, 0],\n",
    "       [1, 0, 1],\n",
    "       [0, 1, 0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33deec33a20f0cd30da411e804e74047",
     "grade": false,
     "grade_id": "cell-a559fbd8ae7bdf62",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_stochatic(G):\n",
    "    ### Ignore division by zero warmings\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9f0cd5f0a94b485832df4dc0c189f53",
     "grade": true,
     "grade_id": "cell-b603cb0d07644bd0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "H = transform_to_stochatic(g)\n",
    "\n",
    "H_res = np.array( \n",
    "[[ 0.,          0.5,         0.5,         0.,          0.,          0.,        ],\n",
    " [ 0.,          0.,          0.,          0.,          0.,          0.,        ],\n",
    " [ 0.33333333,  0.33333333,  0.,          0.,          0.33333333,  0.,        ],\n",
    " [ 0.,          0.,          0.,          0.,          0.5,         0.5,       ],\n",
    " [ 0.,          0.,          0.,          0.5,         0.,          0.5,       ],\n",
    " [ 0.,          0.,          0.,          1.,          0.,          0.,        ]])\n",
    "\n",
    "np.testing.assert_allclose(H, H_res, rtol=1e-4)\n",
    "assert isinstance(H, np.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Finding dangling nodes \n",
    "\n",
    "We want to calculate the \"dangling vector\" $\\mathbf{a}$ which associates with each node the value 1 if this one does not have any outgoing link, and 0 otherwise.\n",
    "\n",
    "(eq. **2**)\n",
    "\n",
    "$$\n",
    "\\mathbf{a}_i = \\begin{cases}\n",
    "    1 & si \\sum_{j} \\mathbf{A}_{ij} = 0 \\\\\n",
    "    0              & \\text{ otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Example**:\n",
    "<img src=\"../../images/DanglingPageRank.png\" width=\"500px\"></img>\n",
    "<div align=\"center\"><b>Fig. 3</b>: the correponding vector $\\mathbf{a}$ of the graph defined in figure 2.</div>\n",
    "\n",
    "# Français\n",
    "## Trouver le dangling vecteur \n",
    "\n",
    "On souhaite calculer le \"dangling vecteur\" $\\mathbf{a}$ qui associe à chaque noeud la valeur 1 si celui-ci ne possède aucun lien de sortie, et 0 sinon.  \n",
    "\n",
    "(eq. **2**)\n",
    "\n",
    "$$\n",
    "\\mathbf{a}_i = \\begin{cases}\n",
    "    1 & si \\sum_{j} \\mathbf{A}_{ij} = 0 \\\\\n",
    "    0              & \\text{ sinon}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Exemple**:\n",
    "<img src=\"../../Images/DanglingPageRank.png\" width=\"500px\"></img>\n",
    "<div align=\"center\"><b>Figure 3</b>: Example de vecteur $\\mathbf{a}$ afin d'identifier les noeuds Dangling</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c34e179bdc0905e6995ebbeac203b9d5",
     "grade": false,
     "grade_id": "cell-16160fe83dc86883",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def dangling_vector(H):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9e41bbbfad5d03b5087ca6e4bcfda98",
     "grade": true,
     "grade_id": "cell-4c9063860247f96f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "a = dangling_vector(H)\n",
    "\n",
    "assert isinstance(a, np.ndarray)\n",
    "np.testing.assert_array_equal(a, [ 0.,  1.,  0.,  0.,  0.,  0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# English\n",
    "## Create the \"Google\" Matrix \n",
    "\n",
    "Unfortunately, the graph of the web does not form a connected graph, which is neither irreducible nor aperiodic. By constructing the \"Google\" matrix, we will add artificial transitions to the adjacency matrix of the web graph in order to transform it into another graph that offers satisfactory properties (irreducible and aperiodic). Once the $ \\mathbf{G}_{n \\times n}$ matrix has been built, it will be used to calculate the steady states $\\pi^T$ (the PageRank) of each node of the graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$. The goal of this exercise is to transform the $\\mathbf{A}_{n \\times n}$ adjacency matrix of the web graph into a matrix $\\mathbf{G}_{n \\times n}$ so that it satisfies the following conditions:\n",
    "\n",
    "1. The matrix $\\mathbf{G}$ should be stochastic. \n",
    "2. The matrix $\\mathbf{G}$ should be irreductible.\n",
    "3. The matrix $\\mathbf{G}$ should be aperiodic.\n",
    "4. The matrix $\\mathbf{G}$ should be primitive. \n",
    "\n",
    "<div class=warn>\n",
    "<b>Definition:</b> A matrix is called primitive if it admits a power whose terms are strictly positive (i.e., there is $ \\mathbf{G}^k > 0 $).\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div class=warn>\n",
    "<b>Theorem:</b> if the matrix $\\mathbf{G}$ is primitive the it exist a vector $\\pi^{(k)T}$ such that $\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(k)T} \\mathbf{G}$. In other words, there is convergence of the vector $\\pi^{(k)}$ to a single stationary state when $k \\to \\infty$, see Perron-Frobenius theorem.\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div class=warn>\n",
    "<b>Theorem of Perron-Frobenius:</b> Let $ \\mathbf{A} $ be a positive and primitive matrix. Then there exist a value $ \\lambda_{max}$ such that:\n",
    "\n",
    "1. $\\lambda_{max}$ is a real positive value, $\\lambda_{max} > 0$ <br>\n",
    "2. $\\lambda_{max}$ is associated to eigenvectors strictly positive <br>\n",
    "3. $\\lambda_{max} > \\lvert \\lambda \\lvert\\ \\ \\forall \\lambda \\neq \\lambda_{max}$ <br>\n",
    "4. it exist a unique vector $\\mathbf{x}$ (with $\\lvert\\lvert \\mathbf{x} \\lvert\\lvert_{1} = 1$) such that  $\\mathbf{A}\\mathbf{x}=\\lambda_{max} \\mathbf{x}$\n",
    "</div>\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "<div class=green>\n",
    "<b>Conclusion:</b> the adjacency matrix $\\mathbf{A}_{n \\times n}$ of an ireductible and aperiodic graph is a primitve matrix. From the Perron-Frobenius theorem, we can conlude that the adjacency matrix $\\mathbf{A}_{n \\times n}$ has an unique vector $\\mathbf{x}$ where all entries are strictly positive and such as $\\mathbf{A}\\mathbf{x}=\\lambda_{max} \\mathbf{x}$.\n",
    "</div>\n",
    "\n",
    "\n",
    "#### We define\n",
    "\n",
    "(eq. **3**)\n",
    "$$\n",
    "\\mathbf{S} = \\mathbf{H} + \\frac{1}{n} \\mathbf{a} \\otimes \\mathbf{e}^T \\\\\n",
    "$$\n",
    "\n",
    "Remider, the vector $\\mathbf{a}_n$ (previously computed) is the dangling vector and $\\mathbf{H}_{n \\times n}$ is the stochastic matrix of the adjacency matrix of the graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (previously computed). \n",
    "\n",
    "#### We define the \"Google matrix\" as follow: \n",
    "\n",
    "(eq. **4**)\n",
    "$$\n",
    "\\mathbf{G} = \\alpha  \\mathbf{S} + (1-\\alpha) \\frac{1}{n}\\mathbf{e} \\otimes \\mathbf{e}^T \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../../images/GoogleMatrice.png\" width=\"500px\"></img>\n",
    "<div align=\"center\"><b>Fig. 4</b>: Google matrice</div>\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "The \"Google matrice\" $\\mathbf{G}_{n \\times n} $ (cf. eq. **4**) is build by adding complementary transitions such as in figure **3** to the original stochastic matric of the graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ in order to satisfy the conditions 2 and 3.\n",
    "\n",
    "# Français\n",
    "## Construction de la \"Google\" Matrice \n",
    "\n",
    "Malheureusement le graphe du web ne forme pas un graphe connexe, irréductible et apériodique. En construisant la matrice \"Google\" on va ajouter à la matrice d'adjacence du graphe du web des transitions artificielles afin de transformer celle-ci en une matrix qui offre des propriétés satisfaisantes (irréductible et apériodique). Une fois la matrice $\\mathbf{G}_{n \\times n}$ construite, elle va permettre de calculer les états stationnaires $\\pi^T$ (le PageRank) de chacun des noeuds du graphe $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$. Le but de cet exercice est de transformer la matrice d'adjacence $\\mathbf{A}_{n \\times n}$ du graphe du web en une matrice $\\mathbf{G}_{n \\times n}$ ($\\mathbf{A} \\to \\mathbf{G}$) de telle sorte qu’elle satisfasse les conditions suivantes: \n",
    "\n",
    "1. Que la matrice $\\mathbf{G}$ soit stochatsique. \n",
    "2. Que la matrice $\\mathbf{G}$ soit irreductible, pour cela il faut qu'il existe un chemin entre tous les noeuds du graphe.\n",
    "3. Que la matrice $\\mathbf{G}$ soit apériodique, l'existence de boucle $\\mathbf{G}_{ii} > 0$ est une condition suffisante pour dire que le graphe est apériodique.\n",
    "4. Que la matrice $\\mathbf{G}$ soit primitive. Si la matrice $\\mathbf{G}$ est primitive alors il existe un vecteur $\\pi^{(k)T}$ tel que $\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(k)T} \\mathbf{G}$ (autrement dit il y a convergence du vecteur $\\pi^{(k)T}$ vers un état stationnaire unique quand $k \\to \\infty$) (cf. théorème de Perron-Frobenius) \n",
    "\n",
    "<div class=warn>\n",
    "<b>Definition 1</b>\n",
    "\n",
    "Une matrice est dite primitive si elle admet une puissance dont tous les termes sont strictement positifs. c.a.d. qu'il existe $\\mathbf{G}^k > 0$\n",
    "</div>\n",
    "\n",
    "<div class=warn>\n",
    "<b>Théorème de Perron-Frobenius</b>\n",
    "\n",
    "Soit une matrice $\\mathbf{A}$ positive et primitive. Alors il existe une valeur propore $\\lambda_{max}$ de telle sorte que: <br>\n",
    "\n",
    "1. $\\lambda_{max}$ est réel et strictment positive, $\\lambda_{max} > 0$ <br>\n",
    "2. à $\\lambda_{max}$ sont associés des vecteurs propres à gauche et à droite strictement positifs <br>\n",
    "3. $\\lambda_{max} > \\lvert \\lambda \\lvert\\ \\ \\forall \\lambda \\neq \\lambda_{max}$ <br>\n",
    "4. il existe un unique vecteur $\\mathbf{x}$ de norme 1 à coordonnées strictement positives tel que $\\mathbf{A}\\mathbf{x}=\\lambda_{max} \\mathbf{x}$\n",
    "</div>\n",
    "\n",
    "<div class=green>\n",
    "<b>Conclusion</b>\n",
    "    \n",
    "La matrice d'ajacence $\\mathbf{A}_{n \\times n}$ d'un graphe irréductible et apériodique est une matrice primitive. Alors d'après le thèoreme de Perron-Frobenius on peut en conclure que la matrice d'adjacence $\\mathbf{A}_{n \\times n}$ admet un unique vecteur $\\mathbf{x}$ de norme 1 à coordonnées strictement positives tel que $\\mathbf{A}\\mathbf{x}=\\lambda_{max} \\mathbf{x}$.\n",
    "</div>\n",
    "\n",
    "On pose :\n",
    "\n",
    "(eq. **3**)\n",
    "$$\n",
    "\\mathbf{S} = \\mathbf{H} + \\frac{1}{n} \\mathbf{a} \\otimes \\mathbf{e}^T \\\\\n",
    "$$\n",
    "\n",
    "Pour rappel, le vecteur $\\mathbf{a}_n$ (calculé à l'étape 3. de l'exercice) est le vecteur Dangling et $\\mathbf{H}_{n \\times n}$ est la matrice normalisée d'adjacence du graphe orienté $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ (calculé à l'étape 2. de l'exercice). On definit la matrice alors la \"Google matrice\" comme étant: \n",
    "\n",
    "(eq. **4**)\n",
    "$$\n",
    "\\mathbf{G} = \\alpha  \\mathbf{S} + (1-\\alpha) \\frac{1}{n}\\mathbf{e} \\otimes \\mathbf{e}^T \\\\\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../../images/GoogleMatrice.png\" width=\"500px\"></img>\n",
    "<div align=\"center\"><b>Fig. 4</b>: Google matrice</div>\n",
    "\n",
    "<br />\n",
    "<br />\n",
    "\n",
    "La \"Google matrice\" $\\mathbf{G}_{n \\times n} $ (cf. eq. 4) est construite en ajoutant des transitions supplémentaires (cf. Fig. 3) à la matrice d'adjacence originale du graphe $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ de telle sorte que les conditions 1 à 3 soient satisfaites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Expand equation 4 (using equation 3) to express the $\\mathbf{G}_{n \\times n}$  as a function of $ \\mathbf{H}_{n \\times n} $ and $ \\mathbf{a}_n $\n",
    "\n",
    "\n",
    "**Response**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aee6d7704346ed61d4a0e3faada49f85",
     "grade": false,
     "grade_id": "cell-a6428e1d936486ec",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def google_matrix(H, a, α=0.9):\n",
    "    '''\n",
    "    H: stochastic adjacency matrix\n",
    "    a : dangling vector\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db913e5604bd01b82edee2c503034d9b",
     "grade": true,
     "grade_id": "cell-879580d18840fc1e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "G = google_matrix(H, a)\n",
    "print(G)\n",
    "\n",
    "G_res = np.array(\n",
    "[[ 0.01666667,  0.46666667,  0.46666667,  0.01666667,  0.01666667,  0.01666667],\n",
    " [ 0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667,  0.16666667],\n",
    " [ 0.31666667,  0.31666667,  0.01666667,  0.01666667,  0.31666667,  0.01666667],\n",
    " [ 0.01666667,  0.01666667,  0.01666667,  0.01666667,  0.46666667,  0.46666667],\n",
    " [ 0.01666667,  0.01666667,  0.01666667,  0.46666667,  0.01666667,  0.46666667],\n",
    " [ 0.01666667,  0.01666667,  0.01666667,  0.91666667,  0.01666667,  0.01666667]])\n",
    "\n",
    "assert isinstance(G, np.ndarray)\n",
    "np.testing.assert_allclose(G, G_res, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Numercial application based on the graph depicted in the figure 2  with $\\alpha = 0.9$\n",
    "\n",
    "(**eq. 4.**)\n",
    "$$\n",
    "\\mathbf{G} = 0.9\\mathbf{H} + \\left[ 0.9 \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{pmatrix} + 0.1  \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ \\end{pmatrix}  \\right]  \\otimes 1/6  \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 & 1 \\end{pmatrix} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{G} =  \\begin{pmatrix} \n",
    "1/60 & 7/15 & 7/15 & 1/60 & 1/60 & 1/60 \\\\\n",
    "1/6  & 1/6  & 1/6  & 1/6  & 1/6  & 1/6 \\\\\n",
    "19/60 & 19/60 & 1/60 & 1/60 & 19/60 & 1/60 \\\\\n",
    "1/60 & 1/60 & 1/60 & 1/60 & 7/15 & 7/15 \\\\\n",
    "1/60 & 1/60 & 1/60 & 7/15 & 1/60 & 7/15 \\\\\n",
    "1/60 & 1/60 & 1/60 & 11/12 & 1/60 & 1/60 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "# Francais\n",
    "## Application numerique pour le graphe décrit dans la figure 2 ($\\alpha = 0.9$)\n",
    "\n",
    "(**eq. 4.**)\n",
    "$$\n",
    "\\mathbf{G} = 0.9\\mathbf{H} + \\left[ 0.9 \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ \\end{pmatrix} + 0.1  \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ \\end{pmatrix}  \\right]  \\otimes 1/6  \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 & 1 \\end{pmatrix} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{G} =  \\begin{pmatrix} \n",
    "1/60 & 7/15 & 7/15 & 1/60 & 1/60 & 1/60 \\\\\n",
    "1/6  & 1/6  & 1/6  & 1/6  & 1/6  & 1/6 \\\\\n",
    "19/60 & 19/60 & 1/60 & 1/60 & 19/60 & 1/60 \\\\\n",
    "1/60 & 1/60 & 1/60 & 1/60 & 7/15 & 7/15 \\\\\n",
    "1/60 & 1/60 & 1/60 & 7/15 & 1/60 & 7/15 \\\\\n",
    "1/60 & 1/60 & 1/60 & 11/12 & 1/60 & 1/60 \\\\\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Compute the PageRank vector\n",
    "\n",
    "(**eq. 5**)\n",
    "\\begin{eqnarray}\n",
    "& \\mathbf{\\pi}^{(k)T} & =   \\mathbf{\\pi}^{(k-1)T} \\mathbf{G} \\\\ \n",
    "& \\mathbf{\\pi}^{(k-1)T} & = \\mathbf{\\pi}^{(k-2)T} \\mathbf{G} \\\\ \n",
    "& \\vdots &\\\\\n",
    "& \\mathbf{\\pi}^{(1)T} & = \\mathbf{\\pi}^{(0)T} \\mathbf{G} \n",
    "\\end{eqnarray}\n",
    "\n",
    "By induction we can therefore write\n",
    "\n",
    "(**eq. 6**)\n",
    "$$\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(0)T} \\mathbf{G}^k$$\n",
    "\n",
    "We now seek to compute the stationary vector $\\mathbf{\\pi}^{(k) T}$ when $k \\ to \\ infty$. We know that the matrix $ \\mathbf{G} $ is primitive by construction, then the converge of the vector $\\mathbf{\\pi}^{T}$ (in the case of a finite state space) is proved by the Perron-Frobenius theorem. In order to calculate the stationary states of the vector $\\mathbf{\\pi}^{T}$ we will then iterate the operation $\\mathbf{\\ pi}^{(k) T} = \\mathbf{\\pi}^{ (k-1) T} \\mathbf{G}$ until convergence of the vector $\\mathbf{\\pi}^{T}$ (cf. Alg 1).\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"../../images/PowerIt.png\" width=\"600px\"></img>\n",
    "\n",
    "<br>\n",
    "<div align=\"center\"><b>Alg1</b>: Power iteration</div>\n",
    "\n",
    "# Français\n",
    "## Calculer la valeur du vecteur PageRank\n",
    "\n",
    "(**eq. 5**)\n",
    "\\begin{eqnarray}\n",
    "& \\mathbf{\\pi}^{(k)T} & =   \\mathbf{\\pi}^{(k-1)T} \\mathbf{G} \\\\ \n",
    "& \\mathbf{\\pi}^{(k-1)T} & = \\mathbf{\\pi}^{(k-2)T} \\mathbf{G} \\\\ \n",
    "& \\vdots &\\\\\n",
    "& \\mathbf{\\pi}^{(1)T} & = \\mathbf{\\pi}^{(0)T} \\mathbf{G} \n",
    "\\end{eqnarray}\n",
    "\n",
    "Par récurence on peut donc écrire \n",
    "\n",
    "(**eq. 6**)\n",
    "$$\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(0)T} \\mathbf{G}^k$$\n",
    "\n",
    "On cherche maintenant à calculé le vecteur stationnaire $\\mathbf{\\pi}^{(k)T}$ lorsque $k \\to \\infty$. On sait que la matrice $\\mathbf{G}$ est primitive par construction, alors la converge du vecteur $\\mathbf{\\pi}^{T}$(dans le cas d'un espace d'état fini) est prouvé par le théorème de Perron-Frobenius. Afin de calculer les états stationaires du vecteur $\\mathbf{\\pi}^{T}$ on va alors itérer l'opération $\\mathbf{\\pi}^{(k)T} = \\mathbf{\\pi}^{(k-1)T} \\mathbf{G}$ jusqu'a convergence du vecteur $\\mathbf{\\pi}^{T}$ (cf. Alg 1).\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"../../images/PowerIt.png\" width=\"600px\"></img>\n",
    "\n",
    "<br>\n",
    "<div align=\"center\"><b>Alg1</b> : Algorithme de calcule iteratif du PageRank</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7855bc6edbfa16cca8846fa7e9ad7b5",
     "grade": false,
     "grade_id": "cell-0f2de665f401ce93",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def power_iter(G, max_iter=500, tol=1.0e-6):\n",
    "    \"\"\"power_iter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : Goole matrix\n",
    "\n",
    "    max_iter : integer, optional\n",
    "        Maxium number of iteration\n",
    "\n",
    "    tol : float, optional\n",
    "       Error tolerance used to check convergence in power method solver.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    raise RuntimeError('pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b03ea38d15584a817bfba4af7de98ff3",
     "grade": true,
     "grade_id": "cell-30e261076683cffa",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(π, gap) = power_iter(G, max_iter=100, tol=1e-6)\n",
    "print(π)\n",
    "\n",
    "# assert the shape is right \n",
    "assert π.shape == (6,)\n",
    "\n",
    "π_res = np.array([ 0.03721313,  0.05395937,  0.04150701,  0.37507848,  0.20599777,  0.28624425])\n",
    "\n",
    "np.testing.assert_allclose(π, π_res, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ, _ = LA.eig(G)\n",
    "λ_2 = np.sort(λ.real)[-2]\n",
    "λ_gap = [λ_2 ** i for i in range(1,25)]\n",
    "\n",
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.semilogy(gap, 'ro')\n",
    "plt.semilogy(λ_gap, lw=2.0, label=\"$\\lambda_2^i$\")\n",
    "plt.title(\"Convergence rate of the PageRank algorithm\")\n",
    "plt.xlabel(\"Number of iteration $(i)$\")\n",
    "plt.ylabel(\"gap\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "print(π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English \n",
    "## Integrate the previously built functions in order to finalize PageRank algorithm\n",
    "\n",
    "Implement the function that integrates the different steps that make up the PageRank algorithm. You should use the functions you have already defined earlier to build the final algorithm.\n",
    "\n",
    "#### Reminder of step need to build the PageRank algorithm\n",
    "1. Normalization of the matrix of ajacence of the graph of the web\n",
    "2. Find the \"Dangling nodes\" (the nodes that don't have any outgoing links)\n",
    "3. Creation of the \"Google\" Matrix\n",
    "4. Calculating the stationary state vector of the Markov chain $\\mathbf{G}$\n",
    "\n",
    "# Français\n",
    "## Intégration des trois étapes qui constituent l'algorithme du PageRank\n",
    "\n",
    "Construire la fonction qui intégre les différentes étapes qui constitutent l'algorithme du PageRank. Vous allez utiliser les fonctions que vous avez définies précedemment pour construire l'algorithme final. \n",
    "\n",
    "**Algorithme du PageRank**\n",
    "1. Normalisation de la matrice d'ajacence du graphe du web\n",
    "2. Découverte des noeuds du graphe du web ne possédant pas de liens de sortie \"Dangling nodes\"(aucun lien hypertext)\n",
    "3. Creation de la \"Google\" Matrice \n",
    "4. Calcul de la vecteur des états stationnaires de la chaine de Markov $\\mathbf{G}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f93633bb468821a384119beb14e0ba3f",
     "grade": false,
     "grade_id": "cell-4db00d895b96dc80",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pagerank(Graph, α=0.85, max_iter=100, tol=1e-6):\n",
    "    \"\"\"Return the PageRank of the nodes in the graph.\n",
    "\n",
    "    PageRank computes a ranking of the nodes in the graph G based on\n",
    "    the structure of the incoming links. It was originally designed as\n",
    "    an algorithm to rank web pages.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    G : graph\n",
    "      A NetworkX graph.  Undirected graphs will be converted to a directed\n",
    "      graph with two directed edges for each undirected edge.\n",
    "\n",
    "    alpha : float, optional\n",
    "      Damping parameter for PageRank, default=0.85.\n",
    "\n",
    "    max_iter : integer, optional\n",
    "      Maximum number of iterations in power method.\n",
    "\n",
    "    tol : float, optional\n",
    "      Error tolerance used to check convergence in power method solver.\n",
    "      \n",
    "    Return\n",
    "    PR : dict\n",
    "      retourne un dictionnaire avec comme clé le nodeid, et comme valeur le pagerank du noeud \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e130eb2b8901bc945487baa044fc572c",
     "grade": true,
     "grade_id": "cell-0fb3eb924a1dcb99",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "PR = pagerank(g)\n",
    "print(PR)\n",
    "\n",
    "PR_res = dict({\n",
    "    1: 0.05170556259095016, \n",
    "    2: 0.07368068204240269, \n",
    "    3: 0.057413363969125462, \n",
    "    4: 0.3487020460725242, \n",
    "    5: 0.1999034157779406, \n",
    "    6: 0.2685949295470571})\n",
    "\n",
    "for k,v in PR_res.items():\n",
    "    np.testing.assert_allclose(PR[k], PR_res[k], rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English \n",
    "## Application of the PageRank: ranking wikipedia article\n",
    "### Load the web graph of Wikipedia\n",
    "\n",
    "# Français \n",
    "## Application de l'algorithme du PageRank pour le classement des pages web\n",
    "### Exemple avec le graphe des liens du site Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the wikipedia graph (networkx)\n",
    "Gwikipedia = nx.read_graphml(\"../../data/Wikipedia/wikipedia.graphml\", node_type=int)\n",
    "#Gwikipedia = nx.read_gpickle(\"../../data/Wikipedia/wikipedia.gpickle\")\n",
    "#Gwikipedia = nx.read_edgelist(\"../../data/Wikipedia/wikipedia.edgelist\", nodetype=int)\n",
    "\n",
    "# load the metadat into a pandas dataframe\n",
    "wikipedia_db = pd.read_pickle(\"../../data/Wikipedia/wikipedia.pkl\")\n",
    "# wikipedia_db = pd.read_csv(\"../../data/Wikipedia/wikipedia.csv\", index_col=\"PageID\")\n",
    "\n",
    "wikipedia_db.head(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English \n",
    "##  Calculate statistical properties of the graph of wikipedia\n",
    "\n",
    "Compute the following:\n",
    "1. the graph density. Reminder, for a graph $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ the density $D =\\vert \\mathcal{E}\\vert/N(N-1)$, \n",
    "2. the degree distribution of the node degree of the wikipedia graph\n",
    "3. the complementary cummulative distribution of the node degree of the wikipedia graph\n",
    "\n",
    "# Français\n",
    "## Calcule des propriété statistique du graphe les liens des pages wikipedia \n",
    "\n",
    "Nous allons calculer:\n",
    "1. la densité du graphe (rappel la densité d'un graphe $\\mathcal{G}(\\mathcal{V}, \\mathcal{E})$ est $D =\\vert \\mathcal{E}\\vert/N(N-1)$) \n",
    "2. la densité de probabilité empirique du degré des noeuds du graphe \n",
    "3. le complémentaire de la fonction de répartition empirique du degré des noeuds du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44dc26d23591d9c2ebb6f748a600e5ca",
     "grade": true,
     "grade_id": "cell-35511977dcf07d47",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# question 1\n",
    "#\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# question 2 & 3: Plot the degree distribution and the complementary cummulative degree distribution\n",
    "#\n",
    "degree = [v for k,v in dict(Gwikipedia.degree()).items()]\n",
    "distribution = [(elem, degree.count(elem)) for elem in sorted(set(degree))]\n",
    "k,pk = zip(*distribution)\n",
    "PDF = np.array(pk)/sum(pk)\n",
    "CCDF = 1-np.cumsum(PDF)\n",
    "\n",
    "\n",
    "#\n",
    "# Plots \n",
    "#\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16/2,9/2))\n",
    "ax1.loglog(k, PDF, 'ro')\n",
    "ax1.set_xlabel(\"$k$ Degree\")\n",
    "ax1.set_ylabel(\"$P_k$\")\n",
    "ax1.set_title(\"PDF\")\n",
    "\n",
    "ax2.loglog(k, CCDF, 'ro')\n",
    "ax2.set_ylim(1e-4,1.1)\n",
    "ax2.set_xlim(1,2e3)\n",
    "ax2.set_xlabel(\"$k$ Degree\")\n",
    "ax2.set_ylabel(\"$1-P[K > k]$\")\n",
    "ax2.set_title(\"CCDF\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English \n",
    "## Questions\n",
    "\n",
    "- Is the wikipedia graph dense ? or sparce ?\n",
    "- What is to say about the degree distribution of the wikipedia graph\n",
    "\n",
    "# Français\n",
    "## Questions\n",
    "\n",
    "- La matrice d'adjacence du graphe est-elle dense ? ou au contraire creuse ?\n",
    "- Que dire de la distribution du degrée des articles wikipedia ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English \n",
    "## Compute the PageRank of a subset of the wikipedia articles\n",
    "\n",
    "# Français\n",
    "## Calculer le PageRank du graphe des articles  Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c5648f4bb12676f0f4bc6dd27fe326c",
     "grade": true,
     "grade_id": "cell-2abb4f66eee73d43",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# compute the pagerank with your previously defined functions\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "PR = [[k,v] for k,v in PR.items()]\n",
    "PR = pd.DataFrame(PR, columns=['PageID', 'PageRank'])\n",
    "PR = PR.set_index('PageID')\n",
    "PR.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We assign a PageRank to each Wikipedia article \n",
    "wikipedia_db = wikipedia_db.join(PR)\n",
    "# We sort the wikipedia article acording to their PageRank\n",
    "wikipedia_db = wikipedia_db.sort_values(['PageRank'], ascending=0)\n",
    "# we print the top ranked wikipedia article \n",
    "wikipedia_db[[\"Page Title\", \"PageRank\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Search Wikipedia article with to keywords\n",
    "\n",
    "**Warning**: the number of wikipedia pages indexed in this database is of the order of 5000 articles only, written in English. The number of articles and therefore of keywords are therefore limited. Perform queries with keywords written in lowercase letters only.\n",
    "\n",
    "# Français\n",
    "## Effectuer une recherche par mots clés sur la base de données des articles Wikipedia\n",
    "\n",
    "**Attention**: le nombre de pages wikipedia indexées dans cette base de données est de l'ordre de 5000 articles seulement, rédigé en anglais. Le nombre d'articles et donc de mots clées sont donc restreints. Effectuer les requêtes avec des mots clés ecrit en lettres minuscules uniquements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyworkds\n",
    "mot_clee_1 = \"france\"\n",
    "mot_clee_2 = \"germany\"\n",
    "# Request\n",
    "wikipedia_db[(wikipedia_db['Keywords'].str.contains(mot_clee_1)==True) & (wikipedia_db['Keywords'].str.contains(mot_clee_2)==True)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords\n",
    "mot_clee_1 = \"france\"\n",
    "# Requete\n",
    "wikipedia_db[(wikipedia_db['Keywords'].str.contains(mot_clee_1)==True) ].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English \n",
    "## Questions\n",
    "\n",
    "Carry out jointly: a query on the database and with the google search engines:\n",
    "\n",
    "* Make a google Request \"site: wikipedia.org keyword1 keyword2\"\n",
    "* Qualitatively compare the requests made on Google and those made on the database\n",
    "\n",
    "# Français\n",
    "## Question\n",
    "\n",
    "Effectuez conjointement: une requête sur la base de donnée et avec le moteurs de recherche de google: \n",
    "\n",
    "* Faite une Requete google \"site:wikipedia.org mot_clée1 mot_clée2\"\n",
    "* Comparer qualitativement les requetes faite sur Google et celles effectués sur la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English\n",
    "## Distributed PageRank\n",
    "\n",
    "The ranking of web pages through the \"PageRank\" algorithm is still considered to be the biggest matrix problem known to date. To give you an order of magnitude, in 2007 the \"power iteration\" which allowed the calculation of PageRank at Google occupied a data center for 15 days to finalize the calculation. In order to reduce the complexity of the computation $\\pi^T \\mathbf{G}$ we would like to perform a computation on a sparse matrix instead of the dense matrix $\\mathbf{G}$. At the same time, one wishes to be able to parallelize computation (multiprocessor, cluster of computation). An elegant way to obtain these two properties is to perform the following operation on all the nodes of the graph (Cf. eq. 7., Fig. 5, Algo. 3):\n",
    "<br>\n",
    "(**eq. 7**)\n",
    "$$ PR_{i} = \\frac{(1-\\alpha)}{n} + \\alpha \\sum_{j \\in \\mathcal{N}^{-}(i)} \\frac{PR_j}{L_j}$$\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/PageRankDistributed2.png\" width=\"400px\"></img>\n",
    "<br />\n",
    "<div align=\"center\"><b>Fig. 5</b>: PageRank</div>\n",
    "</div>\n",
    "\n",
    "The operation described in equation 7. can be computed independently (in parallel) for all the nodes of the graph. This is the approach that is developed in software for calculating large volumes of data such as: \n",
    "\n",
    "* [Spark/Graphx](http://spark.apache.org/)\n",
    "\n",
    "or more simply with certain graphs' libraries of parallel computation:\n",
    "\n",
    "* [boost graph](http://www.boost.org/doc/libs/1_46_0/libs/graph_parallel/doc/html/page_rank.html)\n",
    "* [graph-tool](https://graph-tool.skewed.de/)\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/PageRankDistributed.png\" width=\"500px\"></img>\n",
    "<br />\n",
    "<div align=\"center\"><b>Alg 3</b>: PageRank distributed</div>\n",
    "</div>\n",
    "\n",
    "# Français\n",
    "## Implémentation du PageRank avec un algorithme distribué\n",
    "\n",
    "\n",
    "Le classement des page web au travers de l'algorithme du \"PageRank\" est encore aujourd'hui considéré comme étant le plus gros problème matriciel connu a ce jour. Pour vous donner un ordre de grandeur, en 2007 la \"power iteration\" qui permetait le calcul du PageRank chez Google occupait un datacenter pendant 15 jours pour finaliser le calcul. Afin de reduire la complexité du calcul $\\pi^T \\mathbf{G}$ on souhaiterait effectuer un calcul sur une matrice creuse à la place de la matrice $\\mathbf{G}$ qui est dense. Dans le même temps, on souhaite pouvoir paralléliser le calcul (multiprocesseur, cluster de calcul). Une manière élégante d'obtenir ces deux propriétés est d'éffectuer l'opération suivante sur tout les noeuds du graphe (Cf. eq. 7., Fig. 5, Algo. 3):\n",
    "<br>\n",
    "(**eq. 7**)\n",
    "$$ PR_{i} = \\frac{(1-\\alpha)}{n} + \\alpha \\sum_{j \\in \\mathcal{N}(i)} \\frac{PR_j}{L_j}$$\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/PageRankDistributed2.png\" width=\"400px\"></img>\n",
    "<b>Figure 5.</b>: PageRank \n",
    "</div>\n",
    "\n",
    "L'opération decrite dans l'equation 7. peut être calculer de manière indépendante (en parallèle) pour tous les noeuds du graphes. C'est l'approche qui est développée dans des logiciels pour de calcul de grands volumes de données tels que: \n",
    "\n",
    "* [Spark/Graphx](http://spark.apache.org/)\n",
    "* [Rapids](https://rapids.ai/)\n",
    "\n",
    "ou plus simplement dans certaines librairies de calcul parallèle utilisant la thèorie des graphes:\n",
    "\n",
    "* [boost graph](http://www.boost.org/doc/libs/1_46_0/libs/graph_parallel/doc/html/page_rank.html)\n",
    "* [graph-tool](https://graph-tool.skewed.de/)\n",
    "<br>\n",
    "<br>\n",
    "<div align=\"center\">\n",
    "<img src=\"../../images/PageRankDistributed.png\" width=\"500px\"></img>\n",
    "<b>Algo 3.</b>: Algorithme simplifié du PageRank\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8bafaba098f131088dea27b768f11cd4",
     "grade": false,
     "grade_id": "cell-2143b85bf96cee6b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pagerank_distributed(g, α=0.9, max_iter=200, tol=1.0e-6):\n",
    "    N = g.number_of_nodes()\n",
    "    gc = g.copy()\n",
    "    \n",
    "    # we add the dangling nodes  \n",
    "    for dangling in g.nodes():\n",
    "        if gc.out_degree(dangling) == 0:\n",
    "            for n in g.nodes():\n",
    "                gc.add_edge(dangling, n)\n",
    "\n",
    "    # we initializa the pagerank for each node of the graph\n",
    "    for v in gc.nodes():\n",
    "        gc.nodes[v]['PageRankOld'] = 1.0/N\n",
    "    \n",
    "    # Power iteration\n",
    "    for _ in range(max_iter):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if err < N * tol:\n",
    "            return {n:gc.nodes[n]['PageRank'] for n in gc.nodes()}\n",
    "        \n",
    "    raise RuntimeError('pagerank: power iteration failed to converge in %d iterations.' % max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cebb666848342242b3006453322d328",
     "grade": true,
     "grade_id": "cell-78c2b295e77e9df0",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "PR_dist = pagerank_distributed(g)\n",
    "print(PR)\n",
    "\n",
    "PR_res = dict({\n",
    "    1: 0.0372119873811025, \n",
    "    2: 0.05395738811699192, \n",
    "    3: 0.04150567933532273, \n",
    "    4: 0.37508077029418346, \n",
    "    5: 0.20599832111968525, \n",
    "    6: 0.28624585375271416})\n",
    "\n",
    "for k,v in PR_res.items():\n",
    "    np.testing.assert_allclose(PR_dist[k], PR_res[k], rtol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Amy N. Langville, Carl D. Meyer, \"[Deeper Inside PageRank](http://projecteuclid.org/euclid.im/1109190965)\", Internet Math., Vol. 1(3), pp. 335--380, 2003.\n",
    "\n",
    "[2] Jon Kleinberg, \"[Authoritative sources in a hyperlinked environment](http://www.cs.cornell.edu/home/kleinber/auth.pdf)\",  Journal of the ACM, 46(5), pp. 604–632, 1999.\n",
    "\n",
    "[3] L. Page, S. Brin, R. Motwani, T. Winograd, \"[The PageRank citation ranking: Bringing order to the Web](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf)\", published as a technical report on January 29, 1998."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
